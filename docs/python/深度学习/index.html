<!DOCTYPE html>
<html lang="zh-cn" dir="ltr" class="scroll-smooth" data-default-appearance="dark"
  data-auto-appearance="true"><head>
  <meta charset="utf-8" />
  
  <meta http-equiv="content-language" content="zh-cn" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <meta http-equiv="X-UA-Compatible" content="ie=edge" />
  
  <title>深度学习 &middot; TCmatj的个人博客</title>
  <meta name="title" content="深度学习 &middot; TCmatj的个人博客" />
  
  <meta name="description" content="浙江理工大学" />
  
  
  
  <link rel="canonical" href="https://TCmatj.github.io/docs/python/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" />
  
  
  
  
  
  
  
  
  
  
  <link type="text/css" rel="stylesheet" href="/css/main.bundle.min.85f006de1806b55b2d082d1122deedd8cec6fdc1f7c8a51be975a4496165d6c798f4a3de52545a6a87cc4bc09fc2d6f5201d44ea57acc1ac2b1c42a688c62bee.css"
    integrity="sha512-hfAG3hgGtVstCC0RIt7t2M7G/cH3yKUb6XWkSWFl1seY9KPeUlRaaofMS8Cfwtb1IB1E6leswawrHEKmiMYr7g==" />
  
  
  <script type="text/javascript" src="/js/appearance.min.516a16745bea5a9bd011138d254cc0fd3973cd55ce6e15f3dec763e7c7c2c7448f8fe7b54cca811cb821b0c7e12cd161caace1dd794ac3d34d40937cbcc9ee12.js"
    integrity="sha512-UWoWdFvqWpvQERONJUzA/TlzzVXObhXz3sdj58fCx0SPj&#43;e1TMqBHLghsMfhLNFhyqzh3XlKw9NNQJN8vMnuEg=="></script>
  
  
  
  
  
  
  
  
  
  
  
  
  <script defer type="text/javascript" id="script-bundle" src="/js/main.bundle.min.f5c7687e2a3365a5a366307858918deafa574ab869c626f69dcdd5363e26a725991d0efa1aaaff7ba4b7e2472876189d153d2f9b46a39206caf364407e2aaa77.js"
    integrity="sha512-9cdofiozZaWjZjB4WJGN6vpXSrhpxib2nc3VNj4mpyWZHQ76Gqr/e6S34kcodhidFT0vm0ajkgbK82RAfiqqdw==" data-copy="" data-copied=""></script>
  
  
  <script src="/js/zoom.min.js"></script>
  
  
  
  <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png" />
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png" />
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png" />
  <link rel="manifest" href="/site.webmanifest" />
  
  
  
  
  
  
  
  <meta property="og:url" content="https://TCmatj.github.io/docs/python/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">
  <meta property="og:site_name" content="TCmatj的个人博客">
  <meta property="og:title" content="深度学习">
  <meta property="og:description" content="零、训练 # 1.模型的断点续训练 # 在训练过程中，可能由于某种意">
  <meta property="og:locale" content="zh_cn">
  <meta property="og:type" content="article">
    <meta property="article:section" content="docs">
    <meta property="og:image" content="https://TCmatj.github.io/docs/python/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/featured.png">

  
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:image" content="https://TCmatj.github.io/docs/python/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/featured.png">
  <meta name="twitter:title" content="深度学习">
  <meta name="twitter:description" content="零、训练 # 1.模型的断点续训练 # 在训练过程中，可能由于某种意">

  
  <script type="application/ld+json">
  [{
    "@context": "https://schema.org",
    "@type": "Article",
    "articleSection": "Docs",
    "name": "深度学习",
    "headline": "深度学习",
    
    "abstract": "零、训练 # 1.模型的断点续训练 # 在训练过程中，可能由于某种意",
    "inLanguage": "zh-cn",
    "url" : "https:\/\/TCmatj.github.io\/docs\/python\/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0\/",
    "author" : {
      "@type": "Person",
      "name": "TCmatj"
    },
    
    
    
    
    
    
    
    
    "mainEntityOfPage": "true",
    "wordCount": "12795"
  }]
  </script>


  
  
  <meta name="author" content="TCmatj" />
  
  
  
  <link href="https://github.com/TCmatj" rel="me" />
  
  
  
  

<script src="/lib/jquery/jquery.slim.min.js" integrity=""></script>





















  
  

<script async src="https://www.googletagmanager.com/gtag/js?id=G-PEDMYR1V0K"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-PEDMYR1V0K');
</script>


  
  
  <meta name="theme-color"/>
  
  
  
  <script src="https://www.gstatic.com/firebasejs/8.10.0/firebase-app.js"></script>
  <script src="https://www.gstatic.com/firebasejs/8.10.0/firebase-firestore.js"></script>
  <script src="https://www.gstatic.com/firebasejs/8.10.0/firebase-auth.js"></script>
  <script>

    const firebaseConfig = {
      apiKey: "AIzaSyDe2xnkus6Wsn0D2GU6RKbkRX9exAYhwio",
      authDomain: "AIzaSyDe2xnkus6Wsn0D2GU6RKbkRX9exAYhwio",
      projectId: "blog-53c93",
      storageBucket: "blog-53c93.appspot.com",
      messagingSenderId: "688956731234",
      appId: "1:688956731234:web:3eae3e633a453e1b17063b",
      measurementId: "G-ZXHSY9W6LL"
    };

    var app = firebase.initializeApp(firebaseConfig);
    var db = firebase.firestore();
    var auth = firebase.auth();

  </script>
  
  
</head>
<body
  class="flex flex-col h-screen px-6 m-auto text-lg leading-7 max-w-7xl bg-neutral text-neutral-900 dark:bg-neutral-800 dark:text-neutral sm:px-14 md:px-24 lg:px-32 scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600">
  <div id="the-top" class="absolute flex self-center">
    <a class="px-3 py-1 text-sm -translate-y-8 rounded-b-lg bg-primary-200 focus:translate-y-0 dark:bg-neutral-600"
      href="#main-content"><span
        class="font-bold text-primary-600 ltr:pr-2 rtl:pl-2 dark:text-primary-400">&darr;</span>跳过正文</a>
  </div>
  
  
  <div class="min-h-[148px]"></div>
<div class="fixed inset-x-0 pl-[24px] pr-[24px]" style="z-index:100">
  <div id="menu-blur" class="absolute opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl shadow-2xl"></div>
  <div class="relative max-w-[64rem] ml-auto mr-auto">
    <div style="padding-left:0;padding-right:0;padding-top:2px;padding-bottom:3px"
    class="main-menu flex items-center justify-between px-4 py-6 sm:px-6 md:justify-start space-x-3">
    
    
    
    <div>
        <a href="/" class="flex">
            <span class="sr-only">TCmatj的个人博客</span>

            <img src="/img/blowfish_logo_transparent.png" width="1000" height="1000"
                class="logo max-h-[5rem] max-w-[5rem] object-scale-down object-left nozoom" alt="TCmatj的个人博客" />

        </a>
    </div>
    
    <div class="flex flex-1 items-center justify-between">
        <nav class="flex space-x-3">

            
            <a href="/" class="text-base font-medium text-gray-500 hover:text-gray-900">TCmatj的个人博客</a>
            

        </nav>
        <nav class="hidden md:flex items-center space-x-5 md:ml-12 h-12">

            
            
             
  <div>
  <div class="cursor-pointer flex items-center nested-menu">
    
    <a  class="text-base font-medium text-gray-500 hover:text-primary-600 dark:hover:text-primary-400" title="">
      Java
    </a>
    <span>
      

  <span class="relative block icon">
    <svg
  xmlns="http://www.w3.org/2000/svg"
  viewBox="0 0 20 20"
  fill="currentColor"
  aria-hidden="true"
>
  <path
    fill-rule="evenodd"
    d="M5.23 7.21a.75.75 0 011.06.02L10 11.168l3.71-3.938a.75.75 0 111.08 1.04l-4.25 4.5a.75.75 0 01-1.08 0l-4.25-4.5a.75.75 0 01.02-1.06z"
    clip-rule="evenodd"
  />
</svg>

  </span>


    </span>
  </div>
  <div class="absolute menuhide">
    <div class="pt-2 p-5 mt-2 rounded-xl backdrop-blur shadow-2xl">
      <div class="flex flex-col space-y-3">
        
        <a href="/docs/java/java%E5%9F%BA%E7%A1%80/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Java基础
          </p>
        </a>
        
        <a href="/docs/java/jvm/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            JVM
          </p>
        </a>
        
        <a href="/docs/java/juc/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            JUC
          </p>
        </a>
        
        <a href="/docs/java/stream%E6%B5%81%E4%B8%8Eio%E6%B5%81/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Stream流与IO流
          </p>
        </a>
        
        <a href="/docs/java/springboot/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            SpringBoot
          </p>
        </a>
        
      </div>
    </div>
  </div>
</div>



            
             
  <div>
  <div class="cursor-pointer flex items-center nested-menu">
    
    <a  class="text-base font-medium text-gray-500 hover:text-primary-600 dark:hover:text-primary-400" title="">
      Python
    </a>
    <span>
      

  <span class="relative block icon">
    <svg
  xmlns="http://www.w3.org/2000/svg"
  viewBox="0 0 20 20"
  fill="currentColor"
  aria-hidden="true"
>
  <path
    fill-rule="evenodd"
    d="M5.23 7.21a.75.75 0 011.06.02L10 11.168l3.71-3.938a.75.75 0 111.08 1.04l-4.25 4.5a.75.75 0 01-1.08 0l-4.25-4.5a.75.75 0 01.02-1.06z"
    clip-rule="evenodd"
  />
</svg>

  </span>


    </span>
  </div>
  <div class="absolute menuhide">
    <div class="pt-2 p-5 mt-2 rounded-xl backdrop-blur shadow-2xl">
      <div class="flex flex-col space-y-3">
        
        <a href="/docs/python/python/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Python入门
          </p>
        </a>
        
        <a href="/docs/python/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            机器学习
          </p>
        </a>
        
        <a href="/docs/python/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            深度学习
          </p>
        </a>
        
      </div>
    </div>
  </div>
</div>



            
             
  <div>
  <div class="cursor-pointer flex items-center nested-menu">
    
    <a  class="text-base font-medium text-gray-500 hover:text-primary-600 dark:hover:text-primary-400" title="">
      MySQL
    </a>
    <span>
      

  <span class="relative block icon">
    <svg
  xmlns="http://www.w3.org/2000/svg"
  viewBox="0 0 20 20"
  fill="currentColor"
  aria-hidden="true"
>
  <path
    fill-rule="evenodd"
    d="M5.23 7.21a.75.75 0 011.06.02L10 11.168l3.71-3.938a.75.75 0 111.08 1.04l-4.25 4.5a.75.75 0 01-1.08 0l-4.25-4.5a.75.75 0 01.02-1.06z"
    clip-rule="evenodd"
  />
</svg>

  </span>


    </span>
  </div>
  <div class="absolute menuhide">
    <div class="pt-2 p-5 mt-2 rounded-xl backdrop-blur shadow-2xl">
      <div class="flex flex-col space-y-3">
        
        <a href="/docs/mysql/mysql%E8%AF%AD%E6%B3%95/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            MySQL语法
          </p>
        </a>
        
        <a href="/docs/mysql/mysql%E5%8E%9F%E7%90%86/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            MySQL原理
          </p>
        </a>
        
        <a href="/docs/mysql/mybatis/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            MyBatis
          </p>
        </a>
        
      </div>
    </div>
  </div>
</div>



            
             
  <div>
  <div class="cursor-pointer flex items-center nested-menu">
    
    <a  class="text-base font-medium text-gray-500 hover:text-primary-600 dark:hover:text-primary-400" title="">
      Redis
    </a>
    <span>
      

  <span class="relative block icon">
    <svg
  xmlns="http://www.w3.org/2000/svg"
  viewBox="0 0 20 20"
  fill="currentColor"
  aria-hidden="true"
>
  <path
    fill-rule="evenodd"
    d="M5.23 7.21a.75.75 0 011.06.02L10 11.168l3.71-3.938a.75.75 0 111.08 1.04l-4.25 4.5a.75.75 0 01-1.08 0l-4.25-4.5a.75.75 0 01.02-1.06z"
    clip-rule="evenodd"
  />
</svg>

  </span>


    </span>
  </div>
  <div class="absolute menuhide">
    <div class="pt-2 p-5 mt-2 rounded-xl backdrop-blur shadow-2xl">
      <div class="flex flex-col space-y-3">
        
        <a href="/docs/redis/redis/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Redis入门与原理
          </p>
        </a>
        
        <a href="/docs/redis/lua/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Lua脚本
          </p>
        </a>
        
        <a href="/docs/redis/redis%E4%BD%BF%E7%94%A8/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Redis使用
          </p>
        </a>
        
      </div>
    </div>
  </div>
</div>



            
             
  <div>
  <div class="cursor-pointer flex items-center nested-menu">
    
    <a  class="text-base font-medium text-gray-500 hover:text-primary-600 dark:hover:text-primary-400" title="">
      工具
    </a>
    <span>
      

  <span class="relative block icon">
    <svg
  xmlns="http://www.w3.org/2000/svg"
  viewBox="0 0 20 20"
  fill="currentColor"
  aria-hidden="true"
>
  <path
    fill-rule="evenodd"
    d="M5.23 7.21a.75.75 0 011.06.02L10 11.168l3.71-3.938a.75.75 0 111.08 1.04l-4.25 4.5a.75.75 0 01-1.08 0l-4.25-4.5a.75.75 0 01.02-1.06z"
    clip-rule="evenodd"
  />
</svg>

  </span>


    </span>
  </div>
  <div class="absolute menuhide">
    <div class="pt-2 p-5 mt-2 rounded-xl backdrop-blur shadow-2xl">
      <div class="flex flex-col space-y-3">
        
        <a href="/docs/%E5%B7%A5%E5%85%B7/linux/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Linux
          </p>
        </a>
        
        <a href="/docs/%E5%B7%A5%E5%85%B7/docker/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Docker
          </p>
        </a>
        
        <a href="/docs/%E5%B7%A5%E5%85%B7/maven/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Maven
          </p>
        </a>
        
        <a href="/docs/%E5%B7%A5%E5%85%B7/git/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            Git
          </p>
        </a>
        
      </div>
    </div>
  </div>
</div>



            
             
  <div>
  <div class="cursor-pointer flex items-center nested-menu">
    
    <a  class="text-base font-medium text-gray-500 hover:text-primary-600 dark:hover:text-primary-400" title="">
      其他
    </a>
    <span>
      

  <span class="relative block icon">
    <svg
  xmlns="http://www.w3.org/2000/svg"
  viewBox="0 0 20 20"
  fill="currentColor"
  aria-hidden="true"
>
  <path
    fill-rule="evenodd"
    d="M5.23 7.21a.75.75 0 011.06.02L10 11.168l3.71-3.938a.75.75 0 111.08 1.04l-4.25 4.5a.75.75 0 01-1.08 0l-4.25-4.5a.75.75 0 01.02-1.06z"
    clip-rule="evenodd"
  />
</svg>

  </span>


    </span>
  </div>
  <div class="absolute menuhide">
    <div class="pt-2 p-5 mt-2 rounded-xl backdrop-blur shadow-2xl">
      <div class="flex flex-col space-y-3">
        
        <a href="/docs/%E5%85%B6%E4%BB%96/%E7%8A%B6%E6%80%81%E6%9C%BA/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            状态机
          </p>
        </a>
        
        <a href="/docs/%E5%85%B6%E4%BB%96/%E7%AE%97%E6%B3%95/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            算法
          </p>
        </a>
        
        <a href="/docs/%E5%85%B6%E4%BB%96/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
          
          <p class="text-sm font-sm" title="">
            设计模式
          </p>
        </a>
        
      </div>
    </div>
  </div>
</div>



            
            
  <a href="https://github.com/TCmatj"  target="_blank"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
    
    <span >
        

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>

  </span>


    </span>
    
    <p class="text-base font-medium" title="">
        
    </p>
</a>



            
            

            


            
            <button id="search-button" aria-label="Search" class="text-base hover:text-primary-600 dark:hover:text-primary-400"
                title="">
                

  <span class="relative block icon">
    <svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>

  </span>


            </button>
            


            
            
            <div
                class="ltr:mr-14 rtl:ml-14 flex items-center">
                <button id="appearance-switcher" aria-label="Dark mode switcher" type="button" class="text-base hover:text-primary-600 dark:hover:text-primary-400">
                    <div class="flex items-center justify-center dark:hidden">
                        

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M32 256c0-123.8 100.3-224 223.8-224c11.36 0 29.7 1.668 40.9 3.746c9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3c9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480C132.1 480 32 379.6 32 256z"/></svg>

  </span>


                    </div>
                    <div class="items-center justify-center hidden dark:flex">
                        

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02 0-95.1 42.98-95.1 95.1S202.1 351.1 256 351.1s95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347L446.1 255.1l63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7l-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89L164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6L12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256l-63.15 91.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7l19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109l109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69 0-127.1-57.31-127.1-127.1c0-70.69 57.31-127.1 127.1-127.1s127.1 57.3 127.1 127.1C383.1 326.7 326.7 383.1 256 383.1z"/></svg>

  </span>


                    </div>
                </button>
            </div>
            

        </nav>
        <div class="flex md:hidden items-center space-x-5 md:ml-12 h-12">

            <span></span>

            


            
            <button id="search-button-mobile" aria-label="Search" class="text-base hover:text-primary-600 dark:hover:text-primary-400"
                title="">
                

  <span class="relative block icon">
    <svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>

  </span>


            </button>
            

            
            
            <button id="appearance-switcher-mobile" aria-label="Dark mode switcher" type="button" class="text-base hover:text-primary-600 dark:hover:text-primary-400" style="margin-right:5px">
                <div class="flex items-center justify-center dark:hidden">
                    

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M32 256c0-123.8 100.3-224 223.8-224c11.36 0 29.7 1.668 40.9 3.746c9.616 1.777 11.75 14.63 3.279 19.44C245 86.5 211.2 144.6 211.2 207.8c0 109.7 99.71 193 208.3 172.3c9.561-1.805 16.28 9.324 10.11 16.95C387.9 448.6 324.8 480 255.8 480C132.1 480 32 379.6 32 256z"/></svg>

  </span>


                </div>
                <div class="items-center justify-center hidden dark:flex">
                    

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M256 159.1c-53.02 0-95.1 42.98-95.1 95.1S202.1 351.1 256 351.1s95.1-42.98 95.1-95.1S309 159.1 256 159.1zM509.3 347L446.1 255.1l63.15-91.01c6.332-9.125 1.104-21.74-9.826-23.72l-109-19.7l-19.7-109c-1.975-10.93-14.59-16.16-23.72-9.824L256 65.89L164.1 2.736c-9.125-6.332-21.74-1.107-23.72 9.824L121.6 121.6L12.56 141.3C1.633 143.2-3.596 155.9 2.736 164.1L65.89 256l-63.15 91.01c-6.332 9.125-1.105 21.74 9.824 23.72l109 19.7l19.7 109c1.975 10.93 14.59 16.16 23.72 9.824L256 446.1l91.01 63.15c9.127 6.334 21.75 1.107 23.72-9.822l19.7-109l109-19.7C510.4 368.8 515.6 356.1 509.3 347zM256 383.1c-70.69 0-127.1-57.31-127.1-127.1c0-70.69 57.31-127.1 127.1-127.1s127.1 57.3 127.1 127.1C383.1 326.7 326.7 383.1 256 383.1z"/></svg>

  </span>


                </div>
            </button>
            

        </div>
    </div>
    <div class="-my-2 -mr-2 md:hidden">

        <label id="menu-button" for="menu-controller" class="block">
            <input type="checkbox" id="menu-controller" class="hidden" />
            
            <div class="cursor-pointer hover:text-primary-600 dark:hover:text-primary-400">
                

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M0 96C0 78.33 14.33 64 32 64H416C433.7 64 448 78.33 448 96C448 113.7 433.7 128 416 128H32C14.33 128 0 113.7 0 96zM0 256C0 238.3 14.33 224 32 224H416C433.7 224 448 238.3 448 256C448 273.7 433.7 288 416 288H32C14.33 288 0 273.7 0 256zM416 448H32C14.33 448 0 433.7 0 416C0 398.3 14.33 384 32 384H416C433.7 384 448 398.3 448 416C448 433.7 433.7 448 416 448z"/></svg>

  </span>


            </div>
            <div id="menu-wrapper" style="padding-top:5px;"
                class="fixed inset-0 z-30 invisible w-screen h-screen m-0 overflow-auto transition-opacity opacity-0 cursor-default bg-neutral-100/50 backdrop-blur-sm dark:bg-neutral-900/50">
                <ul
                    class="flex space-y-2 mt-3 flex-col items-end w-full px-6 py-6 mx-auto overflow-visible list-none ltr:text-right rtl:text-left max-w-7xl">

                    <li>
                        <span
                            class="cursor-pointer inline-block align-text-bottom hover:text-primary-600 dark:hover:text-primary-400">

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75 0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3L54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75 0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75 0-45.25s32.75-12.5 45.25 0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25 0s12.5 32.75 0 45.25l-105.4 105.4L310.6 361.4z"/></svg>

  </span>

</span>
                    </li>

                    

                     
  <li class="mt-1">
    <a class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-bg font-bg" title="">
            Java
        </p>
        <span>
            

  <span class="relative block icon">
    <svg
  xmlns="http://www.w3.org/2000/svg"
  viewBox="0 0 20 20"
  fill="currentColor"
  aria-hidden="true"
>
  <path
    fill-rule="evenodd"
    d="M5.23 7.21a.75.75 0 011.06.02L10 11.168l3.71-3.938a.75.75 0 111.08 1.04l-4.25 4.5a.75.75 0 01-1.08 0l-4.25-4.5a.75.75 0 01.02-1.06z"
    clip-rule="evenodd"
  />
</svg>

  </span>


        </span>
    </a>
</li>

<li class="mt-1">
    <a href="/docs/java/java%E5%9F%BA%E7%A1%80/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Java基础
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/docs/java/jvm/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            JVM
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/docs/java/juc/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            JUC
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/docs/java/stream%E6%B5%81%E4%B8%8Eio%E6%B5%81/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Stream流与IO流
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/docs/java/springboot/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            SpringBoot
        </p>
    </a>
</li>

<li class="mb-2"></li>




                    

                     
  <li class="mt-1">
    <a class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-bg font-bg" title="">
            Python
        </p>
        <span>
            

  <span class="relative block icon">
    <svg
  xmlns="http://www.w3.org/2000/svg"
  viewBox="0 0 20 20"
  fill="currentColor"
  aria-hidden="true"
>
  <path
    fill-rule="evenodd"
    d="M5.23 7.21a.75.75 0 011.06.02L10 11.168l3.71-3.938a.75.75 0 111.08 1.04l-4.25 4.5a.75.75 0 01-1.08 0l-4.25-4.5a.75.75 0 01.02-1.06z"
    clip-rule="evenodd"
  />
</svg>

  </span>


        </span>
    </a>
</li>

<li class="mt-1">
    <a href="/docs/python/python/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Python入门
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/docs/python/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            机器学习
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/docs/python/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            深度学习
        </p>
    </a>
</li>

<li class="mb-2"></li>




                    

                     
  <li class="mt-1">
    <a class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-bg font-bg" title="">
            MySQL
        </p>
        <span>
            

  <span class="relative block icon">
    <svg
  xmlns="http://www.w3.org/2000/svg"
  viewBox="0 0 20 20"
  fill="currentColor"
  aria-hidden="true"
>
  <path
    fill-rule="evenodd"
    d="M5.23 7.21a.75.75 0 011.06.02L10 11.168l3.71-3.938a.75.75 0 111.08 1.04l-4.25 4.5a.75.75 0 01-1.08 0l-4.25-4.5a.75.75 0 01.02-1.06z"
    clip-rule="evenodd"
  />
</svg>

  </span>


        </span>
    </a>
</li>

<li class="mt-1">
    <a href="/docs/mysql/mysql%E8%AF%AD%E6%B3%95/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            MySQL语法
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/docs/mysql/mysql%E5%8E%9F%E7%90%86/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            MySQL原理
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/docs/mysql/mybatis/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            MyBatis
        </p>
    </a>
</li>

<li class="mb-2"></li>




                    

                     
  <li class="mt-1">
    <a class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-bg font-bg" title="">
            Redis
        </p>
        <span>
            

  <span class="relative block icon">
    <svg
  xmlns="http://www.w3.org/2000/svg"
  viewBox="0 0 20 20"
  fill="currentColor"
  aria-hidden="true"
>
  <path
    fill-rule="evenodd"
    d="M5.23 7.21a.75.75 0 011.06.02L10 11.168l3.71-3.938a.75.75 0 111.08 1.04l-4.25 4.5a.75.75 0 01-1.08 0l-4.25-4.5a.75.75 0 01.02-1.06z"
    clip-rule="evenodd"
  />
</svg>

  </span>


        </span>
    </a>
</li>

<li class="mt-1">
    <a href="/docs/redis/redis/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Redis入门与原理
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/docs/redis/lua/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Lua脚本
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/docs/redis/redis%E4%BD%BF%E7%94%A8/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Redis使用
        </p>
    </a>
</li>

<li class="mb-2"></li>




                    

                     
  <li class="mt-1">
    <a class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-bg font-bg" title="">
            工具
        </p>
        <span>
            

  <span class="relative block icon">
    <svg
  xmlns="http://www.w3.org/2000/svg"
  viewBox="0 0 20 20"
  fill="currentColor"
  aria-hidden="true"
>
  <path
    fill-rule="evenodd"
    d="M5.23 7.21a.75.75 0 011.06.02L10 11.168l3.71-3.938a.75.75 0 111.08 1.04l-4.25 4.5a.75.75 0 01-1.08 0l-4.25-4.5a.75.75 0 01.02-1.06z"
    clip-rule="evenodd"
  />
</svg>

  </span>


        </span>
    </a>
</li>

<li class="mt-1">
    <a href="/docs/%E5%B7%A5%E5%85%B7/linux/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Linux
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/docs/%E5%B7%A5%E5%85%B7/docker/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Docker
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/docs/%E5%B7%A5%E5%85%B7/maven/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Maven
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/docs/%E5%B7%A5%E5%85%B7/git/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            Git
        </p>
    </a>
</li>

<li class="mb-2"></li>




                    

                     
  <li class="mt-1">
    <a class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-bg font-bg" title="">
            其他
        </p>
        <span>
            

  <span class="relative block icon">
    <svg
  xmlns="http://www.w3.org/2000/svg"
  viewBox="0 0 20 20"
  fill="currentColor"
  aria-hidden="true"
>
  <path
    fill-rule="evenodd"
    d="M5.23 7.21a.75.75 0 011.06.02L10 11.168l3.71-3.938a.75.75 0 111.08 1.04l-4.25 4.5a.75.75 0 01-1.08 0l-4.25-4.5a.75.75 0 01.02-1.06z"
    clip-rule="evenodd"
  />
</svg>

  </span>


        </span>
    </a>
</li>

<li class="mt-1">
    <a href="/docs/%E5%85%B6%E4%BB%96/%E7%8A%B6%E6%80%81%E6%9C%BA/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            状态机
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/docs/%E5%85%B6%E4%BB%96/%E7%AE%97%E6%B3%95/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            算法
        </p>
    </a>
</li>

<li class="mt-1">
    <a href="/docs/%E5%85%B6%E4%BB%96/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <p class="text-sm font-small" title="">
            设计模式
        </p>
    </a>
</li>

<li class="mb-2"></li>




                    

                    
  <li class="mt-1">
    <a href="https://github.com/TCmatj"  target="_blank"  class="flex items-center text-gray-500 hover:text-primary-600 dark:hover:text-primary-400">
        
        <div >
            

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>

  </span>


        </div>
        
        <p class="text-bg font-bg" title="">
            
        </p>
    </a>
</li>




                    

                </ul>
                
                

            </div>
        </label>
    </div>
</div>




<script>
    (function () {
        var $mainmenu = $('.main-menu');
        var path = window.location.pathname;
        $mainmenu.find('a[href="' + path + '"]').each(function (i, e) {
            $(e).children('p').addClass('active');
        });
    })();
</script>


  </div>
</div>
<script>
  window.addEventListener('scroll', function (e) {
    var scroll = window.pageYOffset || document.documentElement.scrollTop || document.body.scrollTop || 0;
    var background_blur = document.getElementById('menu-blur');
    background_blur.style.opacity = (scroll / 300);
  });
</script>

  
  <div class="relative flex flex-col grow">
    <main id="main-content" class="grow">
      


<article>
  
  
  
  
  
  


<div id="hero" class="h-[150px] md:h-[200px]"></div>



    
    <div class="fixed inset-x-0 top-0 h-[800px] single_hero_background nozoom"
    style="background-image:url(/docs/python/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/featured_hu3807e963245fec54257eaebfa39974b0_87923_1200x0_resize_box_3.png);">
    


    <div class="absolute inset-0 bg-gradient-to-t from-neutral dark:from-neutral-800 to-transparent mix-blend-normal">
    </div>
    <div
        class="absolute inset-0 opacity-60 bg-gradient-to-t from-neutral dark:from-neutral-800 to-neutral-100 dark:to-neutral-800 mix-blend-normal">
    </div>
</div>

<div id="background-blur" class="fixed opacity-0 inset-x-0 top-0 h-full single_hero_background nozoom backdrop-blur-2xl"></div>
<script>
    window.addEventListener('scroll', function (e) {
        var scroll = window.pageYOffset || document.documentElement.scrollTop || document.body.scrollTop || 0;
        var background_blur = document.getElementById('background-blur');
        background_blur.style.opacity = (scroll / 300)
    });
</script>

  
  

  <header id="single_header" class="mt-5 max-w-prose">
    
    <ol class="text-sm text-neutral-500 dark:text-neutral-400 print:hidden">
  
  
    
  
    
  
  <li class="inline hidden">
    <a
      class="hover:underline decoration-neutral-300 dark:underline-neutral-600"
      href="/"
      >欢迎来到 Blowfish! :tada:</a
    ><span class="px-1 text-primary-500">/</span>
  </li>

  
  <li class="inline ">
    <a
      class="hover:underline decoration-neutral-300 dark:underline-neutral-600"
      href="/docs/"
      >Docs</a
    ><span class="px-1 text-primary-500">/</span>
  </li>

  
  <li class="inline hidden">
    <a
      class="hover:underline decoration-neutral-300 dark:underline-neutral-600"
      href="/docs/python/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"
      >深度学习</a
    ><span class="px-1 text-primary-500">/</span>
  </li>

</ol>


    
    <h1 class="mt-0 text-4xl font-extrabold text-neutral-900 dark:text-neutral">
      深度学习
    </h1>
    <div class="mt-1 mb-6 text-base text-neutral-500 dark:text-neutral-400 print:hidden">
      





  
  







  





  



  



  



  



  





  



<div class="flex flex-row flex-wrap items-center">
  
  
  <time datetime="0001-01-01 00:00:00 &#43;0000 UTC">0001-01-01</time><span class="px-2 text-primary-500">&middot;</span><span>12795 字</span><span class="px-2 text-primary-500">&middot;</span><span title="预计阅读">26 分钟</span><span class="px-2 text-primary-500">&middot;</span><span>
  
  
    
    
      
      
        
        
      
      
    
  
  <span id="views_docs/Python/深度学习/index.md" class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400" title="views">loading</span>
  <span class="inline-block align-text-bottom">

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512">
<path fill="currentColor" d="M288 32c-80.8 0-145.5 36.8-192.6 80.6C48.6 156 17.3 208 2.5 243.7c-3.3 7.9-3.3 16.7 0 24.6C17.3 304 48.6 356 95.4 399.4C142.5 443.2 207.2 480 288 480s145.5-36.8 192.6-80.6c46.8-43.5 78.1-95.4 93-131.1c3.3-7.9 3.3-16.7 0-24.6c-14.9-35.7-46.2-87.7-93-131.1C433.5 68.8 368.8 32 288 32zM432 256c0 79.5-64.5 144-144 144s-144-64.5-144-144s64.5-144 144-144s144 64.5 144 144zM288 192c0 35.3-28.7 64-64 64c-11.5 0-22.3-3-31.6-8.4c-.2 2.8-.4 5.5-.4 8.4c0 53 43 96 96 96s96-43 96-96s-43-96-96-96c-2.8 0-5.6 .1-8.4 .4c5.3 9.3 8.4 20.1 8.4 31.6z"/></svg>
  </span>

</span>
</span><span class="px-2 text-primary-500">&middot;</span><span>
  
  
    
    
      
      
        
        
      
      
    
  
  <span id="likes_docs/Python/深度学习/index.md"
    class="animate-pulse inline-block text-transparent max-h-3 rounded-full mt-[-2px] align-middle bg-neutral-300 dark:bg-neutral-400"
    title="likes">loading</span>
  <span class="inline-block align-text-bottom">

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512">
<path fill="currentColor" d="M47.6 300.4L228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6 0 115.2 0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"/></svg>
  </span>

</span>
</span><span class="px-2 text-primary-500">&middot;</span><span>
    <button id="button_likes"
        class="rounded-md border border-primary-400 px-1 py-[1px] text-xs font-normal text-primary-700 dark:border-primary-600 dark:text-primary-400"
        onclick="process_article()">
        <span id="button_likes_heart" style="display:none" class="inline-block align-text-bottom">

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512">
<path fill="currentColor" d="M47.6 300.4L228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6 0 115.2 0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"/></svg>
  </span>

 </span>
        <span id="button_likes_emtpty_heart" class="inline-block align-text-bottom">

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512">
<path fill="currentColor" d="M244 84L255.1 96L267.1 84.02C300.6 51.37 347 36.51 392.6 44.1C461.5 55.58 512 115.2 512 185.1V190.9C512 232.4 494.8 272.1 464.4 300.4L283.7 469.1C276.2 476.1 266.3 480 256 480C245.7 480 235.8 476.1 228.3 469.1L47.59 300.4C17.23 272.1 0 232.4 0 190.9V185.1C0 115.2 50.52 55.58 119.4 44.1C164.1 36.51 211.4 51.37 244 84C243.1 84 244 84.01 244 84L244 84zM255.1 163.9L210.1 117.1C188.4 96.28 157.6 86.4 127.3 91.44C81.55 99.07 48 138.7 48 185.1V190.9C48 219.1 59.71 246.1 80.34 265.3L256 429.3L431.7 265.3C452.3 246.1 464 219.1 464 190.9V185.1C464 138.7 430.4 99.07 384.7 91.44C354.4 86.4 323.6 96.28 301.9 117.1L255.1 163.9z"/></svg>
  </span>

</span>
        <span id="button_likes_text">&nbsp;Like</span>
    </button>
</span><span class="px-2 text-primary-500">&middot;</span>


<script type="text/javascript" src="/js/zen-mode.min.63c8a202661f4a2063fdc2706685d668e8ea3da613da2224e9da527e5876e4f53dcac39ab60732626fb4151feae5d430d0cf44731e5d3c726522fcc1519c1547.js" integrity="sha512-Y8iiAmYfSiBj/cJwZoXWaOjqPaYT2iIk6dpSflh25PU9ysOatgcyYm&#43;0FR/q5dQw0M9Ecx5dPHJlIvzBUZwVRw=="></script>

<span class="mb-[2px]">
    <span id="zen-mode-button"
          class="text-lg hover:text-primary-500"
          title=""
          data-title-i18n-disable=""
          data-title-i18n-enable="">
        <span class="inline-block align-text-bottom">

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 50 50" width="50px" height="50px">
    <path fill="currentColor" d="M 12.980469 4 C 9.1204688 4 5.9804688 7.14 5.9804688 11 L 6 26 L 9.9804688 26 L 9.9804688 11 C 9.9804688 9.35 11.320469 8 12.980469 8 L 40.019531 8 C 41.679531 8 43.019531 9.35 43.019531 11 L 43.019531 39 C 43.019531 40.65 41.679531 42 40.019531 42 L 29 42 C 29 43.54 28.420938 44.94 27.460938 46 L 40.019531 46 C 43.879531 46 47.019531 42.86 47.019531 39 L 47.019531 11 C 47.019531 7.14 43.879531 4 40.019531 4 L 12.980469 4 z M 7 28 C 4.794 28 3 29.794 3 32 L 3 42 C 3 44.206 4.794 46 7 46 L 23 46 C 25.206 46 27 44.206 27 42 L 27 32 C 27 29.794 25.206 28 23 28 L 7 28 z M 7 32 L 23 32 L 23.001953 42 L 7 42 L 7 32 z"/>
</svg>
  </span>

</span>
    </span>
</span>
  

  
  
</div>


<div class="flex flex-row flex-wrap items-center">
  
  
  
  
  
  
  
  
  
  
  
</div>




<div class="flex flex-row flex-wrap items-center">
  
  
  
  
  
  
  
  
  
  
  
  
  
</div>



    </div>

    
    
    
    
    

    

    
      
      
        
        
<div class="flex author">
  
    
    
      
    
    
      
        
      
      <img class="!mt-0 !mb-0 h-24 w-24 rounded-full ltr:mr-4 rtl:ml-4" width="96" height="96"
      alt="TCmatj" src="/img/blowfish_logo_hu184ea2fa12490a2458ca388a16ab730e_227816_192x192_fill_box_center_3.png" />
    
  
  <div class="place-self-center">
    
    <div class="text-[0.6rem] uppercase leading-3 text-neutral-500 dark:text-neutral-400">
      作者
    </div>
    <div class="font-semibold leading-6 text-neutral-800 dark:text-neutral-300">
      TCmatj
    </div>
    
    
    <div class="text-sm text-neutral-700 dark:text-neutral-400">浙江理工大学</div>
    
    <div class="text-2xl sm:text-lg">
  <div class="flex flex-wrap text-neutral-400 dark:text-neutral-500">
    
      
        <a
          class="px-1 hover:text-primary-700 dark:hover:text-primary-400"
          href="https://github.com/TCmatj"
          target="_blank"
          aria-label="Github"
          rel="me noopener noreferrer"
          ><span class="inline-block align-text-bottom">

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path fill="currentColor" d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>

  </span>

</span></a
        >
      
    
  </div>

</div>
  </div>
</div>

      

      

      
      <div class="mb-5"></div>
      

    

  </header>
  
  <section class="flex flex-col max-w-full mt-0 prose dark:prose-invert lg:flex-row">
    
     <div
      class="order-first lg:ml-auto px-0 lg:order-last ltr:lg:pl-8 rtl:lg:pr-8">
      <div class="toc ltr:pl-5 rtl:pr-5 print:hidden lg:sticky lg:top-[140px]">

         <details open id="TOCView"
  class="toc-right mt-0 overflow-y-scroll overscroll-contain scrollbar-thin scrollbar-track-neutral-200 scrollbar-thumb-neutral-400 dark:scrollbar-track-neutral-800 dark:scrollbar-thumb-neutral-600 rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 hidden lg:block">
  <summary
    class="block py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">
    目录
  </summary>
  <div
    class="min-w-[220px] py-2 border-dotted ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#零训练">零、训练</a>
      <ul>
        <li><a href="#1模型的断点续训练">1.模型的断点续训练</a></li>
        <li><a href="#2模型-finetune">2.模型 Finetune</a></li>
        <li><a href="#3gpu">3.GPU</a>
          <ul>
            <li><a href="#1使用-gpu-的-tips">1.使用 GPU 的 tips</a></li>
            <li><a href="#2数据并行">2.数据并行</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#一卷积神经网络">一、卷积神经网络</a>
      <ul>
        <li><a href="#1lenet-alexnet架构">1.LeNet 、AlexNet架构</a></li>
        <li><a href="#2vgg">2.VGG</a></li>
        <li><a href="#3nin">3.NIN</a></li>
        <li><a href="#4googlenet">4.GoogLeNet</a></li>
        <li><a href="#5resnet">5.ResNet</a></li>
      </ul>
    </li>
    <li><a href="#二循环神经网络">二、循环神经网络</a>
      <ul>
        <li><a href="#0文本预处理">0.文本预处理</a>
          <ul>
            <li><a href="#1-读取数据集">1. 读取数据集</a></li>
            <li><a href="#2-将文本拆分为单词或字符词元">2. 将文本拆分为单词或字符词元：</a></li>
            <li><a href="#3-构建词表">3. 构建词表</a></li>
            <li><a href="#4-整合">4. 整合</a></li>
          </ul>
        </li>
        <li><a href="#1-文本训练数据集">1. 文本训练数据集</a>
          <ul>
            <li><a href="#1随机采样">1.随机采样</a></li>
            <li><a href="#2顺序分区">2.顺序分区</a></li>
            <li><a href="#3-包装为一个类">3. 包装为一个类</a></li>
          </ul>
        </li>
        <li><a href="#3-困惑度">3. 困惑度</a></li>
        <li><a href="#4rnn">4.RNN</a></li>
        <li><a href="#5门控循环单元gru">5.门控循环单元GRU</a></li>
        <li><a href="#6lstm">6.LSTM</a></li>
        <li><a href="#7编码器解码器架构">7.编码器解码器架构</a></li>
      </ul>
    </li>
    <li><a href="#三注意力机制">三、注意力机制</a>
      <ul>
        <li><a href="#1注意力机制">1.注意力机制</a></li>
        <li><a href="#2加性注意力">2.加性注意力</a></li>
        <li><a href="#3缩放点积注意力">3.缩放点积注意力</a>
          <ul>
            <li><a href="#latex-自带转pdf为svgpdftocairo--svg-sourcepdf"><strong>Latex 自带转PDF为SVG：pdftocairo -svg source.pdf</strong></a></li>
          </ul>
        </li>
        <li><a href="#4多头注意力">4.多头注意力</a></li>
        <li><a href="#5自注意力位置编码">5.自注意力、位置编码</a></li>
        <li><a href="#6transformer">6.Transformer</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</details>
<details class="toc-inside mt-0 overflow-hidden rounded-lg ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 lg:hidden">
  <summary
    class="py-1 text-lg font-semibold cursor-pointer bg-neutral-100 text-neutral-800 ltr:-ml-5 ltr:pl-5 rtl:-mr-5 rtl:pr-5 dark:bg-neutral-700 dark:text-neutral-100 lg:hidden">
    目录
  </summary>
  <div
    class="py-2 border-dotted border-neutral-300 ltr:-ml-5 ltr:border-l ltr:pl-5 rtl:-mr-5 rtl:border-r rtl:pr-5 dark:border-neutral-600">
    <nav id="TableOfContents">
  <ul>
    <li><a href="#零训练">零、训练</a>
      <ul>
        <li><a href="#1模型的断点续训练">1.模型的断点续训练</a></li>
        <li><a href="#2模型-finetune">2.模型 Finetune</a></li>
        <li><a href="#3gpu">3.GPU</a>
          <ul>
            <li><a href="#1使用-gpu-的-tips">1.使用 GPU 的 tips</a></li>
            <li><a href="#2数据并行">2.数据并行</a></li>
          </ul>
        </li>
      </ul>
    </li>
    <li><a href="#一卷积神经网络">一、卷积神经网络</a>
      <ul>
        <li><a href="#1lenet-alexnet架构">1.LeNet 、AlexNet架构</a></li>
        <li><a href="#2vgg">2.VGG</a></li>
        <li><a href="#3nin">3.NIN</a></li>
        <li><a href="#4googlenet">4.GoogLeNet</a></li>
        <li><a href="#5resnet">5.ResNet</a></li>
      </ul>
    </li>
    <li><a href="#二循环神经网络">二、循环神经网络</a>
      <ul>
        <li><a href="#0文本预处理">0.文本预处理</a>
          <ul>
            <li><a href="#1-读取数据集">1. 读取数据集</a></li>
            <li><a href="#2-将文本拆分为单词或字符词元">2. 将文本拆分为单词或字符词元：</a></li>
            <li><a href="#3-构建词表">3. 构建词表</a></li>
            <li><a href="#4-整合">4. 整合</a></li>
          </ul>
        </li>
        <li><a href="#1-文本训练数据集">1. 文本训练数据集</a>
          <ul>
            <li><a href="#1随机采样">1.随机采样</a></li>
            <li><a href="#2顺序分区">2.顺序分区</a></li>
            <li><a href="#3-包装为一个类">3. 包装为一个类</a></li>
          </ul>
        </li>
        <li><a href="#3-困惑度">3. 困惑度</a></li>
        <li><a href="#4rnn">4.RNN</a></li>
        <li><a href="#5门控循环单元gru">5.门控循环单元GRU</a></li>
        <li><a href="#6lstm">6.LSTM</a></li>
        <li><a href="#7编码器解码器架构">7.编码器解码器架构</a></li>
      </ul>
    </li>
    <li><a href="#三注意力机制">三、注意力机制</a>
      <ul>
        <li><a href="#1注意力机制">1.注意力机制</a></li>
        <li><a href="#2加性注意力">2.加性注意力</a></li>
        <li><a href="#3缩放点积注意力">3.缩放点积注意力</a>
          <ul>
            <li><a href="#latex-自带转pdf为svgpdftocairo--svg-sourcepdf"><strong>Latex 自带转PDF为SVG：pdftocairo -svg source.pdf</strong></a></li>
          </ul>
        </li>
        <li><a href="#4多头注意力">4.多头注意力</a></li>
        <li><a href="#5自注意力位置编码">5.自注意力、位置编码</a></li>
        <li><a href="#6transformer">6.Transformer</a></li>
      </ul>
    </li>
  </ul>
</nav>
  </div>
</details>

<script>

  var margin = 200;
  var marginError = 50;

  (function () {
    var $window = $(window);
    var $toc = $('#TOCView');
    var tocHeight = $toc.height();

    function onResize() {
      var windowAndMarginHeight = $window.height() - margin;
      if(tocHeight >= windowAndMarginHeight) {
        $toc.css("overflow-y", "scroll")
        $toc.css("max-height", (windowAndMarginHeight + marginError) + "px")
      } else {
        $toc.css("overflow-y", "hidden")
        $toc.css("max-height", "9999999px")
      }
    }

    $window.on('resize', onResize);
    $(document).ready(onResize);
  })();



  (function () {
    var $toc = $('#TableOfContents');
    if ($toc.length > 0) {
      var $window = $(window);

      function onScroll() {
        var currentScroll = $window.scrollTop();
        var h = $('.anchor');
        var id = "";
        h.each(function (i, e) {
          e = $(e);
          if (e.offset().top - $(window).height()/3 <= currentScroll) {
            id = decodeURIComponent(e.attr('id'));
          }
        });
        var active = $toc.find('a.active');      
        if (active.length == 1 && active.eq(0).attr('href') == '#' + id) return true;

        active.each(function (i, e) {
          
            $(e).removeClass('active');
          
        });
        $toc.find('a[href="#' + id + '"]').addClass('active')
        $toc.find('a[href="#' + id + '"]').parentsUntil('#TableOfContents').each(function (i, e) {
          $(e).children('a').parents('ul').show();          
        });
      }

      $window.on('scroll', onScroll);
      $(document).ready(function () {
        
        onScroll();
      });
    }
  })();


</script>
   </div>
      </div>
      

      <div class="min-w-0 min-h-0 max-w-fit">
        
        


        <div class="article-content max-w-prose mb-20">
          

<h2 class="relative group">零、训练 
    <div id="%E9%9B%B6%E8%AE%AD%E7%BB%83" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#%E9%9B%B6%E8%AE%AD%E7%BB%83" aria-label="锚点">#</a>
    </span>        
    
</h2>


<h3 class="relative group">1.模型的断点续训练 
    <div id="1%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%96%AD%E7%82%B9%E7%BB%AD%E8%AE%AD%E7%BB%83" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#1%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%96%AD%E7%82%B9%E7%BB%AD%E8%AE%AD%E7%BB%83" aria-label="锚点">#</a>
    </span>        
    
</h3>
<p>在训练过程中，可能由于某种意外原因如断点等导致训练终止，这时需要重新开始训练。断点续练是在训练过程中每隔一定次数的 epoch 就保存<strong>模型的参数和优化器的参数</strong>，这样如果意外终止训练了，下次就可以重新加载最新的<strong>模型参数和优化器的参数</strong>，在这个基础上继续训练。</p>
<p>下面的代码中，每隔 5 个 epoch 就保存一次，保存的是一个 dict，包括模型参数、优化器的参数、epoch。然后在 epoch 大于 5 时，就<code>break</code>模拟训练意外终止。关键代码如下：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="k">if</span> <span class="p">(</span><span class="n">epoch</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">checkpoint_interval</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="n">checkpoint</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&#34;model_state_dict&#34;</span><span class="p">:</span> <span class="n">net</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">                  <span class="s2">&#34;optimizer_state_dict&#34;</span><span class="p">:</span> <span class="n">optimizer</span><span class="o">.</span><span class="n">state_dict</span><span class="p">(),</span>
</span></span><span class="line"><span class="cl">                  <span class="s2">&#34;epoch&#34;</span><span class="p">:</span> <span class="n">epoch</span><span class="p">}</span>
</span></span><span class="line"><span class="cl">    <span class="n">path_checkpoint</span> <span class="o">=</span> <span class="s2">&#34;./checkpoint_</span><span class="si">{}</span><span class="s2">_epoch.pkl&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">epoch</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">torch</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">,</span> <span class="n">path_checkpoint</span><span class="p">)</span>
</span></span></code></pre></div><p>断点续训练的恢复代码如下：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="n">path_checkpoint</span> <span class="o">=</span> <span class="s2">&#34;./checkpoint_4_epoch.pkl&#34;</span>
</span></span><span class="line"><span class="cl"><span class="n">checkpoint</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">path_checkpoint</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">net</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;model_state_dict&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">optimizer</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;optimizer_state_dict&#39;</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">start_epoch</span> <span class="o">=</span> <span class="n">checkpoint</span><span class="p">[</span><span class="s1">&#39;epoch&#39;</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">scheduler</span><span class="o">.</span><span class="n">last_epoch</span> <span class="o">=</span> <span class="n">start_epoch</span>
</span></span></code></pre></div><p>需要注意的是，还要设置<code>scheduler.last_epoch</code>参数为保存的 epoch。模型训练的起始 epoch 也要修改为保存的 epoch。</p>


<h3 class="relative group">2.模型 Finetune 
    <div id="2%E6%A8%A1%E5%9E%8B-finetune" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#2%E6%A8%A1%E5%9E%8B-finetune" aria-label="锚点">#</a>
    </span>        
    
</h3>
<p>Finetune 步骤如下：</p>
<ol>
<li>
<p>获取预训练模型的参数</p>
</li>
<li>
<p>使用<code>load_state_dict()</code>把参数加载到模型中</p>
</li>
<li>
<p>修改输出层</p>
</li>
<li>
<p>固定 feature extractor 的参数。这部分通常有 2 种做法：</p>
<ul>
<li>
<p>固定卷积层的预训练参数。可以设置<code>requires_grad=False</code>或者<code>lr=0</code></p>
</li>
<li>
<p>可以通过<code>params_group</code>给 feature extractor 设置一个较小的学习率</p>
</li>
</ul>
</li>
</ol>
<p><strong>冻结卷积层</strong>
设置 <code>requires_grad=False</code> 这里先冻结所有参数，然后再替换全连接层，相当于冻结了卷积层的参数：</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="k">for</span> <span class="n">param</span> <span class="ow">in</span> <span class="n">resnet18_ft</span><span class="o">.</span><span class="n">parameters</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="n">param</span><span class="o">.</span><span class="n">requires_grad</span> <span class="o">=</span> <span class="kc">False</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 首先拿到 fc 层的输入个数</span>
</span></span><span class="line"><span class="cl"><span class="n">num_ftrs</span> <span class="o">=</span> <span class="n">resnet18_ft</span><span class="o">.</span><span class="n">fc</span><span class="o">.</span><span class="n">in_features</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 然后构造新的 fc 层替换原来的 fc 层</span>
</span></span><span class="line"><span class="cl"><span class="n">resnet18_ft</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_ftrs</span><span class="p">,</span> <span class="n">classes</span><span class="p">)</span>
</span></span></code></pre></div>

<h3 class="relative group">3.GPU 
    <div id="3gpu" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#3gpu" aria-label="锚点">#</a>
    </span>        
    
</h3>


<h4 class="relative group">1.使用 GPU 的 tips 
    <div id="1%E4%BD%BF%E7%94%A8-gpu-%E7%9A%84-tips" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#1%E4%BD%BF%E7%94%A8-gpu-%E7%9A%84-tips" aria-label="锚点">#</a>
    </span>        
    
</h4>
<p>PyTorch 模型使用 GPU，可以分为 3 步：</p>
<ol>
<li>首先获取 device：<code>device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)</code></li>
<li>把模型加载到 device：<code>model.to(device)</code></li>
<li>在 data_loader 取数据的循环中，把每个 mini-batch 的数据和 label 加载到 device：<code>inputs, labels = inputs.to(device), labels.to(device)</code></li>
</ol>


<h4 class="relative group">2.数据并行 
    <div id="2%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#2%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C" aria-label="锚点">#</a>
    </span>        
    
</h4>
<p><code>torch.nn.DataParallel(module, device_ids=None, output_device=None, dim=0)</code></p>
<p>功能：可以把数据平均分发到各个 GPU 上，每个 GPU 实际的数据量为 batch_size/GPU 数量，实现并行计算。</p>
<p>主要参数：</p>
<ul>
<li>module：需要包装分发的模型</li>
<li>device_ids：可分发的 GPU，默认分发到所有可见可用的 GPU</li>
<li>output_device：结果输出设备</li>
</ul>
<p>需要注意的是：使用 <code>DataParallel</code> 时，<code>device</code> 要指定某个 GPU 为 主 GPU(放到device_ids第一个)，否则会报错：</p>
<p>RuntimeError: module must have its parameters and buffers on device cuda:1 (device_ids[0]) but found one of them on device: cuda:2</p>
<p>这是因为，使用多 GPU 需要有一个主 GPU，来把每个 batch 的数据分发到每个 GPU，并从每个 GPU 收集计算好的结果。如果不指定主 GPU，那么数据就直接分发到每个 GPU，会造成有些数据在某个 GPU，而另一部分数据在其他 GPU，计算出错</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&#34;cuda:0&#34;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s2">&#34;cpu&#34;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">inputs</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">inputs</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">labels</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">net</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># training</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="n">outputs</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">inputs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s2">&#34;model outputs.size: </span><span class="si">{}</span><span class="s2">&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">outputs</span><span class="o">.</span><span class="n">size</span><span class="p">()))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;CUDA_VISIBLE_DEVICES :</span><span class="si">{}</span><span class="s2">&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&#34;CUDA_VISIBLE_DEVICES&#34;</span><span class="p">]))</span>
</span></span><span class="line"><span class="cl"><span class="nb">print</span><span class="p">(</span><span class="s2">&#34;device_count :</span><span class="si">{}</span><span class="s2">&#34;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">device_count</span><span class="p">()))</span>
</span></span></code></pre></div><p><code>nvidia-smi</code> 命令查看可以 GPU 的利用率，但不能动态刷新显示。如果你想每隔一秒刷新显示 GPU 信息</p>
<p>可以使用<code>watch -n 1 nvidia-smi</code></p>
<p>设置 <code>Dataloader</code>的两个参数：</p>
<ul>
<li>num_workers：默认只使用一个 CPU 读取和处理数据。可以设置为 4、8、16 等参数。但线程数<strong>并不是越大越好</strong>。因为，多核处理需要把数据分发到每个 CPU，处理完成后需要从多个 CPU 收集数据，这个过程也是需要时间的。如果设置<code>num_workers</code>过大，分发和收集数据等操作占用了太多时间，反而会降低效率。</li>
<li>pin_memory：如果内存较大，<strong>建议设置为 True</strong>。
<ul>
<li>设置为 True，表示把数据直接映射到 GPU 的相关内存块上，省掉了一点数据传输时间。</li>
<li>设置为 False，表示从 CPU 传入到缓存 RAM 里面，再给传输到 GPU 上</li>
</ul>
</li>
</ul>


<h2 class="relative group">一、卷积神经网络 
    <div id="%E4%B8%80%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#%E4%B8%80%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C" aria-label="锚点">#</a>
    </span>        
    
</h2>


<h3 class="relative group">1.LeNet 、AlexNet架构 
    <div id="1lenet-alexnet%E6%9E%B6%E6%9E%84" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#1lenet-alexnet%E6%9E%B6%E6%9E%84" aria-label="锚点">#</a>
    </span>        
    
</h3>
<p>
    <figure>
      <img
        class="my-0 rounded-md"
        loading="lazy"
        src="/img/dl_lenet.svg"
        alt="lenet"
      />
      
    </figure>
</p>
<p>
    <figure>
      <img
        class="my-0 rounded-md"
        loading="lazy"
        src="/img/dl_alexnet.svg"
        alt="alexnet"
      />
      
    </figure>
</p>


<h3 class="relative group">2.VGG 
    <div id="2vgg" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#2vgg" aria-label="锚点">#</a>
    </span>        
    
</h3>
<p>
    <figure>
      <img
        class="my-0 rounded-md"
        loading="lazy"
        src="/img/dl_vgg.svg"
        alt="vgg"
      />
      
    </figure>
</p>


<h3 class="relative group">3.NIN 
    <div id="3nin" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#3nin" aria-label="锚点">#</a>
    </span>        
    
</h3>
<p>
    <figure>
      <img
        class="my-0 rounded-md"
        loading="lazy"
        src="/img/dl_nin.svg"
        alt="nin"
      />
      
    </figure>
</p>


<h3 class="relative group">4.GoogLeNet 
    <div id="4googlenet" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#4googlenet" aria-label="锚点">#</a>
    </span>        
    
</h3>
<p>Inception块：</p>
<p>
    <figure>
      <img
        class="my-0 rounded-md"
        loading="lazy"
        src="/img/dl_inception.svg"
        alt="inception"
      />
      
    </figure>
</p>
<p>GoogLeNet网络：</p>
<p>
    <figure>
      <img
        class="my-0 rounded-md"
        loading="lazy"
        src="/img/dl_inception-full.svg"
        alt="inception-full"
      />
      
    </figure>
</p>


<h3 class="relative group">5.ResNet 
    <div id="5resnet" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#5resnet" aria-label="锚点">#</a>
    </span>        
    
</h3>
<p>残差块：</p>
<p>
    <figure>
      <img
        class="my-0 rounded-md"
        loading="lazy"
        src="/img/dl_residual-block.svg"
        alt="residual-block"
      />
      
    </figure>
</p>
<p>ResNet块：</p>
<p>
    <figure>
      <img
        class="my-0 rounded-md"
        loading="lazy"
        src="/img/dl_resnet-block.svg"
        alt="resnet-block"
      />
      
    </figure>
</p>
<p>左右区别：
$$
一种是应用ReLU非线性函数之前，将输入添加到输出。
另一种通过1 \times 1卷积调整通道和分辨率。
$$
ResNet18:</p>
<p>
    <figure>
      <img
        class="my-0 rounded-md"
        loading="lazy"
        src="/img/dl_resnet18.svg"
        alt="resnet18"
      />
      
    </figure>
</p>


<h2 class="relative group">二、循环神经网络 
    <div id="%E4%BA%8C%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#%E4%BA%8C%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C" aria-label="锚点">#</a>
    </span>        
    
</h2>


<h3 class="relative group">0.文本预处理 
    <div id="0%E6%96%87%E6%9C%AC%E9%A2%84%E5%A4%84%E7%90%86" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#0%E6%96%87%E6%9C%AC%E9%A2%84%E5%A4%84%E7%90%86" aria-label="锚点">#</a>
    </span>        
    
</h3>


<h4 class="relative group">1. 读取数据集 
    <div id="1-%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE%E9%9B%86" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#1-%E8%AF%BB%E5%8F%96%E6%95%B0%E6%8D%AE%E9%9B%86" aria-label="锚点">#</a>
    </span>        
    
</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">read_dataset</span><span class="p">():</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;将数据集加载到文本行的列表中&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="s1">&#39;time_machine.txt&#39;</span><span class="p">,</span> <span class="s1">&#39;r&#39;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">lines</span> <span class="o">=</span> <span class="n">f</span><span class="o">.</span><span class="n">readlines</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 正则表达式 [^A-Za-z]+ 将非字母字符替换为空格,strip()去除首尾的空白字符</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="p">[</span><span class="n">re</span><span class="o">.</span><span class="n">sub</span><span class="p">(</span><span class="s1">&#39;[^A-Za-z]+&#39;</span><span class="p">,</span> <span class="s1">&#39; &#39;</span><span class="p">,</span> <span class="n">line</span><span class="p">)</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">]</span>
</span></span></code></pre></div>

<h4 class="relative group">2. 将文本拆分为单词或字符词元： 
    <div id="2-%E5%B0%86%E6%96%87%E6%9C%AC%E6%8B%86%E5%88%86%E4%B8%BA%E5%8D%95%E8%AF%8D%E6%88%96%E5%AD%97%E7%AC%A6%E8%AF%8D%E5%85%83" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#2-%E5%B0%86%E6%96%87%E6%9C%AC%E6%8B%86%E5%88%86%E4%B8%BA%E5%8D%95%E8%AF%8D%E6%88%96%E5%AD%97%E7%AC%A6%E8%AF%8D%E5%85%83" aria-label="锚点">#</a>
    </span>        
    
</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="n">lines</span> <span class="o">=</span> <span class="n">read_dataset</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">tokenize</span><span class="p">(</span><span class="n">lines</span><span class="p">,</span> <span class="n">token</span><span class="o">=</span><span class="s1">&#39;word&#39;</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;将文本行拆分为单词或字符词元&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">token</span> <span class="o">==</span> <span class="s1">&#39;word&#39;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="p">[</span><span class="n">line</span><span class="o">.</span><span class="n">split</span><span class="p">()</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="k">elif</span> <span class="n">token</span> <span class="o">==</span> <span class="s1">&#39;char&#39;</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="p">[</span><span class="nb">list</span><span class="p">(</span><span class="n">line</span><span class="p">)</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">lines</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;错误：未知词元类型：&#39;</span> <span class="o">+</span> <span class="n">token</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenize</span><span class="p">(</span><span class="n">lines</span><span class="p">)</span>
</span></span></code></pre></div>

<h4 class="relative group">3. 构建词表 
    <div id="3-%E6%9E%84%E5%BB%BA%E8%AF%8D%E8%A1%A8" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#3-%E6%9E%84%E5%BB%BA%E8%AF%8D%E8%A1%A8" aria-label="锚点">#</a>
    </span>        
    
</h4>
<p>词元的类型是字符串，而模型需要的输入是数字，因此这种类型不方便模型使用。<em><strong>构建一个字典，通常也叫做</strong>词表</em>（vocabulary），用来将字符串类型的词元映射到从 <em><strong>0</strong></em> 开始的数字索引中。</p>
<ol>
<li>
<p>先将训练集中的所有文档合并在一起，对它们的唯一词元进行统计，得到的统计结果称之为<strong>语料</strong>（corpus）。</p>
</li>
<li>
<p>然后根据每个唯一词元的出现频率，为其分配一个数字索引。很少出现的词元通常被移除，这可以降低复杂性。</p>
</li>
<li>
<p>另外，语料库中不存在或已删除的任何词元都将映射到一个特定的未知词元“&lt;unk&gt;”。</p>
</li>
</ol>
<p>可以选择增加一个列表，用于保存那些被保留的词元，</p>
<p>例如：填充词元（“&lt;pad&gt;”）；</p>
<p>序列开始词元（“&lt;bos&gt;”）；</p>
<p>序列结束词元（“&lt;eos&gt;”）。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">count_corpus</span><span class="p">(</span><span class="n">tokens</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;统计词元的频率&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 这里的tokens是1D列表或2D列表</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">or</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tokens</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="nb">list</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 将词元列表展平成一个列表</span>
</span></span><span class="line"><span class="cl">        <span class="n">tokens</span> <span class="o">=</span> <span class="p">[</span><span class="n">token</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">tokens</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">line</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">collections</span><span class="o">.</span><span class="n">Counter</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span> 	<span class="c1"># 快速计算tokens中每个元素出现的次数，并将结果存储在一个字典中</span>
</span></span><span class="line"><span class="cl">										<span class="c1"># 其中键是元素，值是该元素出现的次数</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Vocab</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;文本词表&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">min_freq</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">reserved_tokens</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">tokens</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">tokens</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">reserved_tokens</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">reserved_tokens</span> <span class="o">=</span> <span class="p">[]</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 按出现频率排序</span>
</span></span><span class="line"><span class="cl">        <span class="n">counter</span> <span class="o">=</span> <span class="n">count_corpus</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">_token_freqs</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">counter</span><span class="o">.</span><span class="n">items</span><span class="p">(),</span> <span class="n">key</span><span class="o">=</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span>	<span class="c1"># 按元素出现次数（键值对中的第二个元素，即x[1]）进行排序</span>
</span></span><span class="line"><span class="cl">                                   <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 未知词元的索引为0</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">idx_to_token</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;&lt;unk&gt;&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="n">reserved_tokens</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 词表初始化</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">token_to_idx</span> <span class="o">=</span> <span class="p">{</span><span class="n">token</span><span class="p">:</span> <span class="n">idx</span>
</span></span><span class="line"><span class="cl">                             <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">token</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">idx_to_token</span><span class="p">)}</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">token</span><span class="p">,</span> <span class="n">freq</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">_token_freqs</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">freq</span> <span class="o">&lt;</span> <span class="n">min_freq</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="k">break</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># 加入词表</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="n">token</span> <span class="ow">not</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_to_idx</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">idx_to_token</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">token</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">token_to_idx</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">idx_to_token</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">idx_to_token</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">tokens</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># 传入的为单个词</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># 若存在，返回对应的索引，若不存在，返回unk索引（0）</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">token_to_idx</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">tokens</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">unk</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">       	<span class="c1"># 多个，递归</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="fm">__getitem__</span><span class="p">(</span><span class="n">token</span><span class="p">)</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">tokens</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">to_tokens</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">indices</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 获取索引对应的词元</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">indices</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># 单个词元</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">idx_to_token</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 递归</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">idx_to_token</span><span class="p">[</span><span class="n">index</span><span class="p">]</span> <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="nd">@property</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">unk</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>  <span class="c1"># 未知词元的索引为0</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="mi">0</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="nd">@property</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">token_freqs</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_token_freqs</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">vocab</span> <span class="o">=</span> <span class="n">Vocab</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 将文本行转换为一个数字索引列表</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">]:</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;文本:&#39;</span><span class="p">,</span> <span class="n">tokens</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;索引:&#39;</span><span class="p">,</span> <span class="n">vocab</span><span class="p">[</span><span class="n">tokens</span><span class="p">[</span><span class="n">i</span><span class="p">]])</span>
</span></span></code></pre></div>

<h4 class="relative group">4. 整合 
    <div id="4-%E6%95%B4%E5%90%88" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#4-%E6%95%B4%E5%90%88" aria-label="锚点">#</a>
    </span>        
    
</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">load_corpus</span><span class="p">(</span><span class="n">max_tokens</span><span class="o">=-</span><span class="mi">1</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;返回数据集的词元索引列表和词表&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">lines</span> <span class="o">=</span> <span class="n">read_dataset</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">tokens</span> <span class="o">=</span> <span class="n">tokenize</span><span class="p">(</span><span class="n">lines</span><span class="p">,</span> <span class="s1">&#39;char&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">vocab</span> <span class="o">=</span> <span class="n">Vocab</span><span class="p">(</span><span class="n">tokens</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 因为时光机器数据集中的每个文本行不一定是一个句子或一个段落，还可能是一个单词</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 因此返回的corpus仅处理为单个列表，而不是使用多词元列表构成的一个列表</span>
</span></span><span class="line"><span class="cl">    <span class="n">corpus</span> <span class="o">=</span> <span class="p">[</span><span class="n">vocab</span><span class="p">[</span><span class="n">token</span><span class="p">]</span> <span class="k">for</span> <span class="n">line</span> <span class="ow">in</span> <span class="n">tokens</span> <span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">line</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">max_tokens</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">corpus</span> <span class="o">=</span> <span class="n">corpus</span><span class="p">[:</span><span class="n">max_tokens</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">corpus</span><span class="p">,</span> <span class="n">vocab</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">corpus</span><span class="p">,</span> <span class="n">vocab</span> <span class="o">=</span> <span class="n">load_corpus</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="nb">len</span><span class="p">(</span><span class="n">corpus</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)</span>
</span></span></code></pre></div>

<h3 class="relative group">1. 文本训练数据集 
    <div id="1-%E6%96%87%E6%9C%AC%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E9%9B%86" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#1-%E6%96%87%E6%9C%AC%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E9%9B%86" aria-label="锚点">#</a>
    </span>        
    
</h3>
<p>输出 <em><strong>Y</strong></em> 相较于输入 <em><strong>X</strong></em> 往右移一个词元</p>


<h4 class="relative group">1.随机采样 
    <div id="1%E9%9A%8F%E6%9C%BA%E9%87%87%E6%A0%B7" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#1%E9%9A%8F%E6%9C%BA%E9%87%87%E6%A0%B7" aria-label="锚点">#</a>
    </span>        
    
</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">seq_data_iter_random</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;使用随机抽样生成一个小批量子序列&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 从随机偏移量开始对序列进行分区，随机范围包括num_steps-1</span>
</span></span><span class="line"><span class="cl">    <span class="n">corpus</span> <span class="o">=</span> <span class="n">corpus</span><span class="p">[</span><span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_steps</span> <span class="o">-</span> <span class="mi">1</span><span class="p">):]</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 减去1，是因为我们需要考虑标签。——子序列个数</span>
</span></span><span class="line"><span class="cl">    <span class="n">num_subseqs</span> <span class="o">=</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">num_steps</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 长度为num_steps的子序列的起始索引</span>
</span></span><span class="line"><span class="cl">    <span class="n">initial_indices</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_subseqs</span> <span class="o">*</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 在随机抽样的迭代过程中，</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 来自两个相邻的、随机的、小批量中的子序列不一定在原始序列上相邻</span>
</span></span><span class="line"><span class="cl">    <span class="n">random</span><span class="o">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">initial_indices</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">data</span><span class="p">(</span><span class="n">pos</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 返回从pos位置开始的长度为num_steps的序列</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">corpus</span><span class="p">[</span><span class="n">pos</span><span class="p">:</span> <span class="n">pos</span> <span class="o">+</span> <span class="n">num_steps</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">	<span class="c1"># ——批次数</span>
</span></span><span class="line"><span class="cl">    <span class="n">num_batches</span> <span class="o">=</span> <span class="n">num_subseqs</span> <span class="o">//</span> <span class="n">batch_size</span>	
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">batch_size</span> <span class="o">*</span> <span class="n">num_batches</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 在这里，initial_indices包含子序列的随机起始索引</span>
</span></span><span class="line"><span class="cl">        <span class="n">initial_indices_per_batch</span> <span class="o">=</span> <span class="n">initial_indices</span><span class="p">[</span><span class="n">i</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">batch_size</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">X</span> <span class="o">=</span> <span class="p">[</span><span class="n">data</span><span class="p">(</span><span class="n">j</span><span class="p">)</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">initial_indices_per_batch</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">Y</span> <span class="o">=</span> <span class="p">[</span><span class="n">data</span><span class="p">(</span><span class="n">j</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="n">initial_indices_per_batch</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="k">yield</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">      
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl"><span class="c1">##########################    </span>
</span></span><span class="line"><span class="cl"><span class="n">my_seq</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">35</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="ow">in</span> <span class="n">seq_data_iter_random</span><span class="p">(</span><span class="n">my_seq</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">num_steps</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;X: &#39;</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Y:&#39;</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
</span></span></code></pre></div>

<h4 class="relative group">2.顺序分区 
    <div id="2%E9%A1%BA%E5%BA%8F%E5%88%86%E5%8C%BA" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#2%E9%A1%BA%E5%BA%8F%E5%88%86%E5%8C%BA" aria-label="锚点">#</a>
    </span>        
    
</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">seq_data_iter_sequential</span><span class="p">(</span><span class="n">corpus</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;使用顺序分区生成一个小批量子序列&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 从随机偏移量开始划分序列</span>
</span></span><span class="line"><span class="cl">    <span class="n">offset</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">num_tokens</span> <span class="o">=</span> <span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span> <span class="o">-</span> <span class="n">offset</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="n">batch_size</span><span class="p">)</span> <span class="o">*</span> <span class="n">batch_size</span>
</span></span><span class="line"><span class="cl">    <span class="n">Xs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">corpus</span><span class="p">[</span><span class="n">offset</span><span class="p">:</span> <span class="n">offset</span> <span class="o">+</span> <span class="n">num_tokens</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="n">Ys</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">corpus</span><span class="p">[</span><span class="n">offset</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span> <span class="n">offset</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">num_tokens</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="n">Xs</span><span class="p">,</span> <span class="n">Ys</span> <span class="o">=</span> <span class="n">Xs</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">),</span> <span class="n">Ys</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">num_batches</span> <span class="o">=</span> <span class="n">Xs</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">//</span> <span class="n">num_steps</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_steps</span> <span class="o">*</span> <span class="n">num_batches</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">X</span> <span class="o">=</span> <span class="n">Xs</span><span class="p">[:,</span> <span class="n">i</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">num_steps</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="n">Y</span> <span class="o">=</span> <span class="n">Ys</span><span class="p">[:,</span> <span class="n">i</span><span class="p">:</span> <span class="n">i</span> <span class="o">+</span> <span class="n">num_steps</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="k">yield</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span>
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl">        
</span></span><span class="line"><span class="cl"><span class="c1">########################## </span>
</span></span><span class="line"><span class="cl"><span class="n">my_seq</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">35</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="ow">in</span> <span class="n">seq_data_iter_sequential</span><span class="p">(</span><span class="n">my_seq</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">num_steps</span><span class="o">=</span><span class="mi">5</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;X: &#39;</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="s1">&#39;</span><span class="se">\n</span><span class="s1">Y:&#39;</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
</span></span></code></pre></div>

<h4 class="relative group">3. 包装为一个类 
    <div id="3-%E5%8C%85%E8%A3%85%E4%B8%BA%E4%B8%80%E4%B8%AA%E7%B1%BB" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#3-%E5%8C%85%E8%A3%85%E4%B8%BA%E4%B8%80%E4%B8%AA%E7%B1%BB" aria-label="锚点">#</a>
    </span>        
    
</h4>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-python" data-lang="python"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">SeqDataLoader</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;加载序列数据的迭代器&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">use_random_iter</span><span class="p">,</span> <span class="n">max_tokens</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">use_random_iter</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">data_iter_fn</span> <span class="o">=</span> <span class="n">seq_data_iter_random</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">data_iter_fn</span> <span class="o">=</span> <span class="n">seq_data_iter_sequential</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">corpus</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab</span> <span class="o">=</span> <span class="n">load_corpus</span><span class="p">(</span><span class="n">max_tokens</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_steps</span> <span class="o">=</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__iter__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">data_iter_fn</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">corpus</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_steps</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">load_data</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">use_random_iter</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">max_tokens</span><span class="o">=</span><span class="mi">10000</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;返回数据集的迭代器和词表&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">data_iter</span> <span class="o">=</span> <span class="n">SeqDataLoader</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">use_random_iter</span><span class="p">,</span> <span class="n">max_tokens</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">data_iter</span><span class="p">,</span> <span class="n">data_iter</span><span class="o">.</span><span class="n">vocab</span>
</span></span></code></pre></div>

<h3 class="relative group">3. 困惑度 
    <div id="3-%E5%9B%B0%E6%83%91%E5%BA%A6" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#3-%E5%9B%B0%E6%83%91%E5%BA%A6" aria-label="锚点">#</a>
    </span>        
    
</h3>
<p>语言模型应该能让我们更准确地预测下一个词元。</p>
<p>因此，它应该允许我们在压缩序列时花费更少的比特。</p>
<p>所以我们可以通过一个序列中所有的 <em><strong>n</strong></em> 个词元的交叉熵损失的平均值来衡量：
$$
\frac{1}{n} \sum_{t=1}^n -\log P(x_t \mid x_{t-1}, \ldots, x_1)
$$
其中 <strong>P</strong> 由语言模型给出，<strong>x_t</strong> 是在时间步 <strong>t</strong> 从该序列中观察到的实际词元。这使得不同长度的文档的性能具有了可比性。</p>
<p>由于历史原因，自然语言处理的科学家更喜欢使用一个叫做<strong>困惑度</strong>（perplexity）的量。</p>
<p>简而言之，它是上面的指数：
$$
\exp\left(-\frac{1}{n} \sum_{t=1}^n \log P(x_t \mid x_{t-1}, \ldots, x_1)\right).
$$
困惑度的最好的理解是“下一个词元的实际选择数的调和平均数”。</p>
<p>* 在<strong>最好</strong>的情况下，模型总是完美地估计标签词元的概率为1。在这种情况下，模型的<strong>困惑度为1</strong>。</p>
<p>* 在<strong>最坏</strong>的情况下，模型总是预测标签词元的概率为0。在这种情况下，困惑度是<strong>正无穷大</strong>。</p>
<p>* 在<strong>基线上</strong>，该模型的预测是词表的所有可用词元上的均匀分布。 在这种情况下，困惑度等于词表中<strong>唯一词元的数量</strong>。</p>
<p>使用困惑度来评估模型。</p>


<h3 class="relative group">4.RNN 
    <div id="4rnn" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#4rnn" aria-label="锚点">#</a>
    </span>        
    
</h3>
<p>
    <figure>
      <img
        class="my-0 rounded-md"
        loading="lazy"
        src="/img/dl_rnn.svg"
        alt="rnn"
      />
      
    </figure>

$$
时间步t的隐藏变量：\mathbf{H}<em>t = \phi(\mathbf{X}<em>t \mathbf{W}</em>{xh} + \mathbf{H}</em>{t-1} \mathbf{W}_{hh}  + \mathbf{b}_h).\
时间步t的输出：\mathbf{O}<em>t = \mathbf{H}<em>t \mathbf{W}</em>{hq} + \mathbf{b}<em>q.\
循环神经网络的参数包括隐藏层的权重
\mathbf{W}</em>{xh} \in \mathbb{R}^{d \times h}, \mathbf{W}</em>{hh} \in \mathbb{R}^{h \times h}和偏置\mathbf{b}<em>h \in \mathbb{R}^{1 \times h}，\
以及输出层的权重\mathbf{W}</em>{hq} \in \mathbb{R}^{h \times q}
和偏置\mathbf{b}_q \in \mathbb{R}^{1 \times q}\
d为输入的独热编码的长度，h为隐藏层的长度，q为输出的长度\
对于\mathbf{X}_t \in \mathbb{R}^{n \times d},输出\mathbf{O}_t\in \mathbb{R}^{n \times q}
$$
训练过程：</p>
<p>
    <figure>
      <img
        class="my-0 rounded-md"
        loading="lazy"
        src="/img/dl_rnn-train.svg"
        alt="rnn-train"
      />
      
    </figure>
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">35</span>
</span></span><span class="line"><span class="cl"><span class="n">train_iter</span><span class="p">,</span> <span class="n">vocab</span> <span class="o">=</span> <span class="n">load_data</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="n">num_hiddens</span> <span class="o">=</span> <span class="mi">256</span>
</span></span><span class="line"><span class="cl"><span class="n">rnn_layer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">RNN</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">),</span> <span class="n">num_hiddens</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 初始化隐藏状态</span>
</span></span><span class="line"><span class="cl"><span class="n">state</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">state</span><span class="o">.</span><span class="n">shape</span>	<span class="c1"># torch.Size([1, 32, 256])（隐藏层数，批量大小，隐藏单元数）</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1">#通过一个隐状态和一个输入，我们就可以用更新后的隐状态计算输出</span>
</span></span><span class="line"><span class="cl"><span class="c1">#需要强调的是rnn_layer的“输出”（Y）不涉及输出层的计算：</span>
</span></span><span class="line"><span class="cl"><span class="c1">#它是指每个时间步的隐状态，这些隐状态可以用作后续输出层的输入。</span>
</span></span><span class="line"><span class="cl"><span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">num_steps</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">)))</span>
</span></span><span class="line"><span class="cl"><span class="n">Y</span><span class="p">,</span> <span class="n">state_new</span> <span class="o">=</span> <span class="n">rnn_layer</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="c1"># Y是隐状态</span>
</span></span><span class="line"><span class="cl"><span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">state_new</span><span class="o">.</span><span class="n">shape</span> <span class="c1"># (torch.Size([35, 32, 256]), torch.Size([1, 32, 256]))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">RNNModel</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;循环神经网络模型&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rnn_layer</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">(</span><span class="n">RNNModel</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">rnn_layer</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span> <span class="o">=</span> <span class="n">vocab_size</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">hidden_size</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 如果RNN是双向的（之后将介绍），num_directions应该是2，否则应该是1</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">bidirectional</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">num_directions</span> <span class="o">=</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">num_directions</span> <span class="o">=</span> <span class="mi">2</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">inputs</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">X</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">inputs</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">long</span><span class="p">(),</span> <span class="bp">self</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">Y</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 全连接层首先将Y的形状改为(时间步数*批量大小,隐藏单元数)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 它的输出形状是(时间步数*批量大小,词表大小)。</span>
</span></span><span class="line"><span class="cl">        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">Y</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">Y</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])))</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">state</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">begin_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">LSTM</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># nn.GRU以张量作为隐状态</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span>  <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">num_directions</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">num_layers</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                                 <span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                                <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># nn.LSTM以元组作为隐状态</span>
</span></span><span class="line"><span class="cl">            <span class="k">return</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span>
</span></span><span class="line"><span class="cl">                <span class="bp">self</span><span class="o">.</span><span class="n">num_directions</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">num_layers</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                <span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                    <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span>
</span></span><span class="line"><span class="cl">                        <span class="bp">self</span><span class="o">.</span><span class="n">num_directions</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="o">.</span><span class="n">num_layers</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                        <span class="n">batch_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span><span class="p">),</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="c1"># 训练与预测 </span>
</span></span><span class="line"><span class="cl"><span class="n">device</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">net</span> <span class="o">=</span> <span class="n">RNNModel</span><span class="p">(</span><span class="n">rnn_layer</span><span class="p">,</span> <span class="n">vocab_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">vocab</span><span class="p">))</span>
</span></span><span class="line"><span class="cl"><span class="n">net</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">d2l</span><span class="o">.</span><span class="n">predict_ch8</span><span class="p">(</span><span class="s1">&#39;time traveller&#39;</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 训练</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">train_epoch</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">updater</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">use_random_iter</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;训练网络一个迭代周期（定义见第8章）&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">state</span><span class="p">,</span> <span class="n">timer</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Timer</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">metric</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Accumulator</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># 训练损失之和,词元数量</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span> <span class="ow">in</span> <span class="n">train_iter</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">state</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">use_random_iter</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># 在第一次迭代或使用随机抽样时初始化state</span>
</span></span><span class="line"><span class="cl">            <span class="n">state</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">begin_state</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">)</span> <span class="ow">and</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">state</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">                <span class="c1"># state对于nn.GRU是个张量</span>
</span></span><span class="line"><span class="cl">                <span class="n">state</span><span class="o">.</span><span class="n">detach_</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                <span class="c1"># state对于nn.LSTM或对于我们从零开始实现的模型是个张量</span>
</span></span><span class="line"><span class="cl">                <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">state</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">                    <span class="n">s</span><span class="o">.</span><span class="n">detach_</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="n">y</span> <span class="o">=</span> <span class="n">Y</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">y_hat</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">l</span> <span class="o">=</span> <span class="n">loss</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">long</span><span class="p">())</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">updater</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">updater</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="n">l</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="n">grad_clipping</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="n">updater</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">l</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">            <span class="n">grad_clipping</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># 因为已经调用了mean函数</span>
</span></span><span class="line"><span class="cl">            <span class="n">updater</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">metric</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">l</span> <span class="o">*</span> <span class="n">y</span><span class="o">.</span><span class="n">numel</span><span class="p">(),</span> <span class="n">y</span><span class="o">.</span><span class="n">numel</span><span class="p">())</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">math</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">metric</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">/</span> <span class="n">metric</span><span class="p">[</span><span class="mi">1</span><span class="p">]),</span> <span class="n">metric</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">/</span> <span class="n">timer</span><span class="o">.</span><span class="n">stop</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="c1"># 预测</span>
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">prefix</span><span class="p">,</span> <span class="n">num_preds</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">device</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;在prefix后面生成新字符&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">state</span> <span class="o">=</span> <span class="n">net</span><span class="o">.</span><span class="n">begin_state</span><span class="p">(</span><span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">outputs</span> <span class="o">=</span> <span class="p">[</span><span class="n">vocab</span><span class="p">[</span><span class="n">prefix</span><span class="p">[</span><span class="mi">0</span><span class="p">]]]</span>
</span></span><span class="line"><span class="cl">    <span class="n">get_input</span> <span class="o">=</span> <span class="k">lambda</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">outputs</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">prefix</span><span class="p">[</span><span class="mi">1</span><span class="p">:]:</span>  <span class="c1"># 预热期</span>
</span></span><span class="line"><span class="cl">        <span class="n">_</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">get_input</span><span class="p">(),</span> <span class="n">state</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">vocab</span><span class="p">[</span><span class="n">y</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_preds</span><span class="p">):</span>  <span class="c1"># 预测num_preds步</span>
</span></span><span class="line"><span class="cl">        <span class="n">y</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">net</span><span class="p">(</span><span class="n">get_input</span><span class="p">(),</span> <span class="n">state</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">outputs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">)))</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">([</span><span class="n">vocab</span><span class="o">.</span><span class="n">idx_to_token</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">outputs</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">              <span class="n">use_random_iter</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;训练模型&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">    <span class="n">animator</span> <span class="o">=</span> <span class="n">d2l</span><span class="o">.</span><span class="n">Animator</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s1">&#39;epoch&#39;</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s1">&#39;perplexity&#39;</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                            <span class="n">legend</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;train&#39;</span><span class="p">],</span> <span class="n">xlim</span><span class="o">=</span><span class="p">[</span><span class="mi">10</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 初始化</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">updater</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">updater</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">batch_size</span><span class="p">:</span> <span class="n">d2l</span><span class="o">.</span><span class="n">sgd</span><span class="p">(</span><span class="n">net</span><span class="o">.</span><span class="n">params</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="n">predict</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">prefix</span><span class="p">:</span> <span class="n">predict</span><span class="p">(</span><span class="n">prefix</span><span class="p">,</span> <span class="mi">50</span><span class="p">,</span> <span class="n">net</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 训练和预测</span>
</span></span><span class="line"><span class="cl">    <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_epochs</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">ppl</span><span class="p">,</span> <span class="n">speed</span> <span class="o">=</span> <span class="n">train_epoch</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">net</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">updater</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">use_random_iter</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">10</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="nb">print</span><span class="p">(</span><span class="n">predict</span><span class="p">(</span><span class="s1">&#39;time traveller&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">            <span class="n">animator</span><span class="o">.</span><span class="n">add</span><span class="p">(</span><span class="n">epoch</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="p">[</span><span class="n">ppl</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;困惑度 </span><span class="si">{</span><span class="n">ppl</span><span class="si">:</span><span class="s1">.1f</span><span class="si">}</span><span class="s1">, </span><span class="si">{</span><span class="n">speed</span><span class="si">:</span><span class="s1">.1f</span><span class="si">}</span><span class="s1"> 词元/秒 </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="n">device</span><span class="p">)</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="n">predict</span><span class="p">(</span><span class="s1">&#39;time traveller&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    <span class="nb">print</span><span class="p">(</span><span class="n">predict</span><span class="p">(</span><span class="s1">&#39;traveller&#39;</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl"><span class="n">num_epochs</span><span class="p">,</span> <span class="n">lr</span> <span class="o">=</span> <span class="mi">500</span><span class="p">,</span> <span class="mi">1</span>
</span></span><span class="line"><span class="cl"><span class="n">train</span><span class="p">(</span><span class="n">net</span><span class="p">,</span> <span class="n">train_iter</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">lr</span><span class="p">,</span> <span class="n">num_epochs</span><span class="p">,</span> <span class="n">d2l</span><span class="o">.</span><span class="n">try_gpu</span><span class="p">())</span>
</span></span></code></pre></div>

<h3 class="relative group">5.门控循环单元GRU 
    <div id="5%E9%97%A8%E6%8E%A7%E5%BE%AA%E7%8E%AF%E5%8D%95%E5%85%83gru" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#5%E9%97%A8%E6%8E%A7%E5%BE%AA%E7%8E%AF%E5%8D%95%E5%85%83gru" aria-label="锚点">#</a>
    </span>        
    
</h3>
<p><strong>重置门和更新门</strong></p>
<p>
    <figure>
      <img
        class="my-0 rounded-md"
        loading="lazy"
        src="/img/dl_gru-1.svg"
        alt="gru-1"
      />
      
    </figure>

$$
对于给定的时间步t，假设输入是一个小批量
\mathbf{X}<em>t \in \mathbb{R}^{n \times d}（样本个数n，输入个数d），\
上一个时间步的隐状态是\mathbf{H}</em>{t-1} \in \mathbb{R}^{n \times h}（隐藏单元个数h）。\
那么，重置门\mathbf{R}_t \in \mathbb{R}^{n \times h}和
更新门\mathbf{Z}_t \in \mathbb{R}^{n \times h}的计算如下所示：\</p>
<p>\begin{aligned}
\mathbf{R}<em>t = \sigma(\mathbf{X}<em>t \mathbf{W}</em>{xr} + \mathbf{H}</em>{t-1} \mathbf{W}<em>{hr} + \mathbf{b}<em>r),\
\mathbf{Z}<em>t = \sigma(\mathbf{X}<em>t \mathbf{W}</em>{xz} + \mathbf{H}</em>{t-1} \mathbf{W}</em>{hz} + \mathbf{b}<em>z),
\end{aligned}
\
其中\mathbf{W}</em>{xr}, \mathbf{W}</em>{xz} \in \mathbb{R}^{d \times h}
和\mathbf{W}<em>{hr}, \mathbf{W}</em>{hz} \in \mathbb{R}^{h \times h}是权重参数，
\mathbf{b}_r, \mathbf{b}_z \in \mathbb{R}^{1 \times h}是偏置参数。\
请注意，在求和过程中会触发广播机制，使用sigmoid函数将输入值转换到区间(0, 1)。
$$
<strong>候选隐状态</strong></p>
<p>
    <figure>
      <img
        class="my-0 rounded-md"
        loading="lazy"
        src="/img/dl_gru-2.svg"
        alt="dl_gru-2"
      />
      
    </figure>

$$
将重置门\mathbf{R}_t与常规隐状态更新机制集成，得到在时间步t的候选隐状态（candidate hidden state）\tilde{\mathbf{H}}_t \in \mathbb{R}^{n \times h}。\</p>
<p>\tilde{\mathbf{H}}<em>t = \tanh(\mathbf{X}<em>t \mathbf{W}</em>{xh} + \left(\mathbf{R}<em>t \odot \mathbf{H}</em>{t-1}\right) \mathbf{W}</em>{hh} + \mathbf{b}_h),\</p>
<p>其中\mathbf{W}<em>{xh} \in \mathbb{R}^{d \times h}
和\mathbf{W}</em>{hh} \in \mathbb{R}^{h \times h}是权重参数，
\mathbf{b}_h \in \mathbb{R}^{1 \times h}是偏置项，
符号\odot是Hadamard积（按元素乘积）运算符。\
使用tanh非线性激活函数来确保候选隐状态中的值保持在区间(-1, 1)中。\</p>
<p>\mathbf{R}<em>t和\mathbf{H}</em>{t-1}的元素相乘可以减少以往状态的影响。每当重置门\mathbf{R}_t中的项接近1时，恢复一个普通的循环神经网络。\
对于重置门\mathbf{R}_t中所有接近0的项，候选隐状态是以\mathbf{X}_t作为输入的多层感知机的结果。因此，任何预先存在的隐状态都会被重置为默认值。
$$
<strong>隐状态</strong></p>
<p>
    <figure>
      <img
        class="my-0 rounded-md"
        loading="lazy"
        src="/img/dl_gru-3.svg"
        alt="dl_gru-3"
      />
      
    </figure>

$$
上述的计算结果只是候选隐状态，我们仍然需要结合更新门\mathbf{Z}_t的效果。\
这一步确定新的隐状态\mathbf{H}<em>t \in \mathbb{R}^{n \times h}在多大程度上来自旧的状态\mathbf{H}</em>{t-1}和
新的候选状态\tilde{\mathbf{H}}_t。\
更新门\mathbf{Z}<em>t仅需要在\mathbf{H}</em>{t-1}和\tilde{\mathbf{H}}_t之间进行按元素的凸组合就可以实现这个目标。\
这就得出了门控循环单元的最终更新公式：\</p>
<p>\mathbf{H}_t = \mathbf{Z}<em>t \odot \mathbf{H}</em>{t-1}  + (1 - \mathbf{Z}_t) \odot \tilde{\mathbf{H}}_t.\</p>
<p>每当更新门\mathbf{Z}_t接近1时，模型就倾向只保留旧状态。此时，来自\mathbf{X}_t的信息基本上被忽略，从而有效地跳过了依赖链条中的时间步t。\
相反，当\mathbf{Z}_t接近0时，新的隐状态\mathbf{H}_t就会接近候选隐状态\tilde{\mathbf{H}}_t。\
这些设计可以帮助我们处理循环神经网络中的梯度消失问题，并更好地捕获时间步距离很长的序列的依赖关系。\
例如，如果整个子序列的所有时间步的更新门都接近于1，在序列起始时间步的旧隐状态都将很容易保留并传递到序列结束。
$$
总之，门控循环单元具有以下两个显著特征：</p>
<ul>
<li>
<p>重置门有助于捕获序列中的短期依赖关系；</p>
</li>
<li>
<p>更新门有助于捕获序列中的长期依赖关系。</p>
</li>
</ul>


<h3 class="relative group">6.LSTM 
    <div id="6lstm" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#6lstm" aria-label="锚点">#</a>
    </span>        
    
</h3>
<p><strong>输入门、忘记门和输出门</strong></p>
<p>
    <figure>
      <img
        class="my-0 rounded-md"
        loading="lazy"
        src="/img/dl_lstm-0.svg"
        alt="dl_lstm-0"
      />
      
    </figure>

$$
\begin{flalign}
&amp;假设有h个隐藏单元，批量大小为n，输入数为d。\
&amp;因此，输入为\mathbf{X}<em>t \in \mathbb{R}^{n \times d}，
前一时间步的隐状态为\mathbf{H}</em>{t-1} \in \mathbb{R}^{n \times h}。\
&amp;相应地，时间步t的门被定义如下：\
&amp;输入门是\mathbf{I}_t \in \mathbb{R}^{n \times h}，\
&amp;遗忘门是\mathbf{F}_t \in \mathbb{R}^{n \times h}，\
&amp;输出门是\mathbf{O}_t \in \mathbb{R}^{n \times h}。\</p>
<p>&amp;它们的计算方法如下：\
\mathbf{I}<em>t &amp;= \sigma(\mathbf{X}<em>t \mathbf{W}</em>{xi} + \mathbf{H}</em>{t-1} \mathbf{W}_{hi} + \mathbf{b}<em>i),\
\mathbf{F}<em>t &amp;= \sigma(\mathbf{X}<em>t \mathbf{W}</em>{xf} + \mathbf{H}</em>{t-1} \mathbf{W}</em>{hf} + \mathbf{b}<em>f),\
\mathbf{O}<em>t &amp;= \sigma(\mathbf{X}<em>t \mathbf{W}</em>{xo} + \mathbf{H}</em>{t-1} \mathbf{W}</em>{ho} + \mathbf{b}_o),\</p>
<p>&amp;其中\mathbf{W}<em>{xi}, \mathbf{W}</em>{xf}, \mathbf{W}<em>{xo} \in \mathbb{R}^{d \times h}
和\mathbf{W}</em>{hi}, \mathbf{W}<em>{hf}, \mathbf{W}</em>{ho} \in \mathbb{R}^{h \times h}是权重参数，
\mathbf{b}_i, \mathbf{b}_f, \mathbf{b}_o \in \mathbb{R}^{1 \times h}是偏置参数。
\end{flalign}
$$
<strong>候选记忆元</strong></p>
<p>
    <figure>
      <img
        class="my-0 rounded-md"
        loading="lazy"
        src="/img/dl_lstm-1.svg"
        alt="dl_lstm-1"
      />
      
    </figure>

$$
\tilde{\mathbf{C}}_t \in \mathbb{R}^{n \times h}
它的计算与上面描述的三个门的计算类似，
但是使用\tanh函数作为激活函数，函数的值范围为(-1, 1)。\
下面导出在时间步t处的方程：\</p>
<p>\tilde{\mathbf{C}}<em>t = \text{tanh}(\mathbf{X}<em>t \mathbf{W}</em>{xc} + \mathbf{H}</em>{t-1} \mathbf{W}_{hc} + \mathbf{b}_c),\</p>
<p>其中\mathbf{W}<em>{xc} \in \mathbb{R}^{d \times h}和\mathbf{W}</em>{hc} \in \mathbb{R}^{h \times h}是权重参数，\mathbf{b}_c \in \mathbb{R}^{1 \times h}是偏置参数。
$$</p>
<p><strong>记忆元</strong></p>
<p>
    <figure>
      <img
        class="my-0 rounded-md"
        loading="lazy"
        src="/img/dl_lstm-2.svg"
        alt="lstm-2"
      />
      
    </figure>

$$
在门控循环单元中，有一种机制来控制输入和遗忘（或跳过）。\
类似地，在长短期记忆网络中，也有两个门用于这样的目的：\
输入门\mathbf{I}_t控制采用多少来自\tilde{\mathbf{C}}_t的新数据，\
而遗忘门\mathbf{F}<em>t控制保留多少过去的记忆元\mathbf{C}</em>{t-1} \in \mathbb{R}^{n \times h}的内容。\
使用按元素乘法，得出：\</p>
<p>\mathbf{C}_t = \mathbf{F}<em>t \odot \mathbf{C}</em>{t-1} + \mathbf{I}_t \odot \tilde{\mathbf{C}}_t.\</p>
<p>如果遗忘门始终为1且输入门始终为0，则过去的记忆元\mathbf{C}_{t-1}将随时间被保存并传递到当前时间步。\
引入这种设计是为了缓解梯度消失问题，并更好地捕获序列中的长距离依赖关系。
$$
<strong>隐状态</strong></p>
<p>
    <figure>
      <img
        class="my-0 rounded-md"
        loading="lazy"
        src="/img/dl_lstm-3.svg"
        alt="dl_lstm-3"
      />
      
    </figure>

$$
最后，我们需要定义如何计算隐状态\mathbf{H}_t \in \mathbb{R}^{n \times h}，
这就是输出门发挥作用的地方。\
在长短期记忆网络中，它仅仅是记忆元的\tanh的门控版本。这就确保了\mathbf{H}_t的值始终在区间(-1, 1)内：\</p>
<p>\mathbf{H}_t = \mathbf{O}_t \odot \tanh(\mathbf{C}_t).\</p>
<p>只要输出门接近1，我们就能够有效地将所有记忆信息传递给预测部分，\
而对于输出门接近0，我们只保留记忆元内的所有信息，而不需要更新隐状态。\
$$</p>


<h3 class="relative group">7.编码器解码器架构 
    <div id="7%E7%BC%96%E7%A0%81%E5%99%A8%E8%A7%A3%E7%A0%81%E5%99%A8%E6%9E%B6%E6%9E%84" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#7%E7%BC%96%E7%A0%81%E5%99%A8%E8%A7%A3%E7%A0%81%E5%99%A8%E6%9E%B6%E6%9E%84" aria-label="锚点">#</a>
    </span>        
    
</h3>
<p><strong>编码器</strong>（encoder）：接受一个长度可变的序列作为输入，并将其转换为具有固定形状的编码状态。</p>
<p><strong>解码器</strong>（decoder）：将固定形状的编码状态映射到长度可变的序列。</p>
<p>这被称为<strong>编码器-解码器</strong>（encoder-decoder）架构:</p>
<p>
    <figure>
      <img class="my-0 rounded-md" loading="lazy" src="#ZgotmplZ" alt="dl_encoder-decoder" />
      
    </figure>
</p>
<p>在编码器接口中，我们只指定长度可变的序列作为编码器的输入<code>X</code>。任何继承这个<code>Encoder</code>基类的模型将完成代码实现。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Encoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;编码器-解码器架构的基本编码器接口&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">(</span><span class="n">Encoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span></span></code></pre></div><p>在下面的解码器接口中，新增一个<code>init_state</code>函数，用于将编码器的输出（<code>enc_outputs</code>）转换为编码后的状态。</p>
<p>注意，此步骤可能需要额外的输入，例如：输入序列的有效长度。为了逐个地生成长度可变的词元序列，解码器在每个时间步都会将输入（例如：在前一时间步生成的词元）和编码后的状态映射成当前时间步的输出词元。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Decoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;编码器-解码器架构的基本解码器接口&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">(</span><span class="n">Decoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">init_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_outputs</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">raise</span> <span class="ne">NotImplementedError</span>
</span></span></code></pre></div><p><strong>合并</strong></p>
<p>“编码器-解码器”架构包含了一个编码器和一个解码器，并且还拥有可选的额外的参数。</p>
<p>在前向传播中，编码器的输出用于生成编码状态，这个状态又被解码器作为其输入的一部分。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">EncoderDecoder</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;编码器-解码器架构的基类&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">encoder</span><span class="p">,</span> <span class="n">decoder</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">(</span><span class="n">EncoderDecoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span> <span class="o">=</span> <span class="n">encoder</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span> <span class="o">=</span> <span class="n">decoder</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_X</span><span class="p">,</span> <span class="n">dec_X</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">enc_outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">encoder</span><span class="p">(</span><span class="n">enc_X</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">dec_state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="o">.</span><span class="n">init_state</span><span class="p">(</span><span class="n">enc_outputs</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">decoder</span><span class="p">(</span><span class="n">dec_X</span><span class="p">,</span> <span class="n">dec_state</span><span class="p">)</span>
</span></span></code></pre></div><p><strong>seq2seq</strong></p>
<p>
    <figure>
      <img class="my-0 rounded-md" loading="lazy" src="#ZgotmplZ" alt="dl_seq2seq" />
      
    </figure>
</p>
<p>特定的“&lt;eos&gt;”表示序列结束词元。一旦输出序列生成此词元，模型就会停止预测。</p>
<p>在循环神经网络解码器的初始化时间步，有两个特定的设计决定：</p>
<ul>
<li>
<p>首先，特定的“&lt;bos&gt;”表示序列开始词元，它是解码器的输入序列的第一个词元。</p>
</li>
<li>
<p>其次，使用循环神经网络编码器最终的隐状态来初始化解码器的隐状态。</p>
</li>
</ul>
<p>例如，在 <code>Sutskever.Vinyals.Le.2014</code>的设计中，正是基于这种设计将输入序列的编码信息送入到解码器中来生成输出序列的。</p>
<p>如上图所示，编码器最终的隐状态在每一个时间步都作为解码器的输入序列的一部分。可以允许标签成为原始的输出序列，从源序列词元“&lt;bos&gt;”“Ils”“regardent”“.”到新序列词元“Ils”“regardent”“.”“&lt;eos&gt;”来移动预测的位置。</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Seq2SeqEncoder</span><span class="p">(</span><span class="n">Encoder</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;用于序列到序列学习的循环神经网络编码器&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                 <span class="n">dropout</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">(</span><span class="n">Seq2SeqEncoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 嵌入层</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                          <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 输出&#39;X&#39;的形状：(batch_size,num_steps,embed_size)</span>
</span></span><span class="line"><span class="cl">        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 在循环神经网络模型中，第一个轴对应于时间步</span>
</span></span><span class="line"><span class="cl">        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 如果未提及状态，则默认为0</span>
</span></span><span class="line"><span class="cl">        <span class="n">output</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># output的形状:(num_steps,batch_size,num_hiddens)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># state的形状:(num_layers,batch_size,num_hiddens)如果使用LSTM，将包含记忆单元信息</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">state</span>
</span></span><span class="line"><span class="cl"> 
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">Seq2SeqDecoder</span><span class="p">(</span><span class="n">Decoder</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;用于序列到序列学习的循环神经网络解码器&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                 <span class="n">dropout</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">(</span><span class="n">Seq2SeqDecoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embed_size</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">GRU</span><span class="p">(</span><span class="n">embed_size</span> <span class="o">+</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                          <span class="n">dropout</span><span class="o">=</span><span class="n">dropout</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">init_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_outputs</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">enc_outputs</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 输出&#39;X&#39;的形状：(batch_size,num_steps,embed_size)</span>
</span></span><span class="line"><span class="cl">        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">X</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 广播context，使其具有与X相同的num_steps</span>
</span></span><span class="line"><span class="cl">        <span class="n">context</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">X_and_context</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">X</span><span class="p">,</span> <span class="n">context</span><span class="p">),</span> <span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">output</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">rnn</span><span class="p">(</span><span class="n">X_and_context</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">output</span><span class="p">)</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># output的形状:(batch_size,num_steps,vocab_size)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># state的形状:(num_layers,batch_size,num_hiddens)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">output</span><span class="p">,</span> <span class="n">state</span>
</span></span></code></pre></div><p>
    <figure>
      <img class="my-0 rounded-md" loading="lazy" src="#ZgotmplZ" alt="dl_seq2seq-details" />
      
    </figure>
</p>
<p><strong>预测：</strong></p>
<p>
    <figure>
      <img class="my-0 rounded-md" loading="lazy" src="#ZgotmplZ" alt="dl_seq2seq-predict" />
      
    </figure>
</p>


<h2 class="relative group">三、注意力机制 
    <div id="%E4%B8%89%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#%E4%B8%89%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6" aria-label="锚点">#</a>
    </span>        
    
</h2>


<h3 class="relative group">1.注意力机制 
    <div id="1%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#1%E6%B3%A8%E6%84%8F%E5%8A%9B%E6%9C%BA%E5%88%B6" aria-label="锚点">#</a>
    </span>        
    
</h3>
<p>
    <figure>
      <img
        class="my-0 rounded-md"
        loading="lazy"
        src="/img/dl_qkv.svg"
        alt="dl_qkv"
      />
      
    </figure>
</p>
<p><strong>非参数注意力池化层</strong></p>
<hr>
<p>$$
f(x) = \sum_{i=1}^n \frac{K(x - x_i)}{\sum_{j=1}^n K(x - x_j)} y_i
$$</p>
<p><em>高斯核</em>（Gaussian kernel），其定义为：
$$
K(u) = \frac{1}{\sqrt{2\pi}} \exp(-\frac{u^2}{2}).
$$</p>
<p>将高斯核代入可以得到：</p>
<p>$$
\begin{aligned} f(x) &amp;=\sum_{i=1}^n \alpha(x, x_i) y_i\ &amp;= \sum_{i=1}^n \frac{\exp\left(-\frac{1}{2}(x - x_i)^2\right)}{\sum_{j=1}^n \exp\left(-\frac{1}{2}(x - x_j)^2\right)} y_i \&amp;= \sum_{i=1}^n \mathrm{softmax}\left(-\frac{1}{2}(x - x_i)^2\right) y_i. \end{aligned}
$$</p>
<p><strong>带参数注意力汇聚</strong>
$$
\begin{aligned}f(x) &amp;= \sum_{i=1}^n \alpha(x, x_i) y_i \&amp;= \sum_{i=1}^n \frac{\exp\left(-\frac{1}{2}((x - x_i)w)^2\right)}{\sum_{j=1}^n \exp\left(-\frac{1}{2}((x - x_j)w)^2\right)} y_i \&amp;= \sum_{i=1}^n \mathrm{softmax}\left(-\frac{1}{2}((x - x_i)w)^2\right) y_i.\end{aligned}
$$</p>
<p><strong>注意力分数</strong></p>
<p>
    <figure>
      <img
        class="my-0 rounded-md"
        loading="lazy"
        src="/img/dl_attention-output.svg"
        alt="dl_attention-output"
      />
      
    </figure>

$$
用数学语言描述，假设有一个查询\mathbf{q} \in \mathbb{R}^q和
m个 键-值 对(\mathbf{k}_1, \mathbf{v}_1), \ldots, (\mathbf{k}_m, \mathbf{v}_m)，其中\mathbf{k}_i \in \mathbb{R}^k，\mathbf{v}_i \in \mathbb{R}^v。\
注意力汇聚函数f就被表示成值的加权和：\</p>
<p>f(\mathbf{q}, (\mathbf{k}_1, \mathbf{v}_1), \ldots, (\mathbf{k}_m, \mathbf{v}<em>m)) = \sum</em>{i=1}^m \alpha(\mathbf{q}, \mathbf{k}_i) \mathbf{v}_i \in \mathbb{R}^v,\</p>
<p>其中查询\mathbf{q}和键\mathbf{k}_i的注意力权重（标量）
是通过注意力评分函数a将两个向量映射成标量，
再经过softmax运算得到的：\</p>
<p>\alpha(\mathbf{q}, \mathbf{k}_i) = \mathrm{softmax}(a(\mathbf{q}, \mathbf{k}_i)) = \frac{\exp(a(\mathbf{q}, \mathbf{k}<em>i))}{\sum</em>{j=1}^m \exp(a(\mathbf{q}, \mathbf{k}_j))} \in \mathbb{R}.
$$</p>


<h3 class="relative group">2.加性注意力 
    <div id="2%E5%8A%A0%E6%80%A7%E6%B3%A8%E6%84%8F%E5%8A%9B" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#2%E5%8A%A0%E6%80%A7%E6%B3%A8%E6%84%8F%E5%8A%9B" aria-label="锚点">#</a>
    </span>        
    
</h3>
<p>$$
a(\mathbf q, \mathbf k) = \mathbf w_v^\top \text{tanh}(\mathbf W_q\mathbf q + \mathbf W_k \mathbf k) \in \mathbb{R},\</p>
<p>其中可学习的参数是\mathbf W_q\in\mathbb R^{h\times q}、
\mathbf W_k\in\mathbb R^{h\times k}和
\mathbf w_v\in\mathbb R^{h}。
$$
相当于keys、values 合并之后放入隐藏层大小为 h、输出层为 1 的 MLP</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">sequence_mask</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">valid_len</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="mi">0</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;在序列中屏蔽不相关的项&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">maxlen</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 创建一个包含从 0 到 maxlen-1 的张量表示序列的位置索引</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># [None, :]：通过添加维度，将上述张量从一维变为二维，形状为 (1, maxlen)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 广播，将 valid_len 张量从一维转换为二维，并与上述张量进行逐元素比较</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># mask[i, j] 表示序列中位置索引为 j 的元素是否属于有效长度范围内的元素</span>
</span></span><span class="line"><span class="cl">    <span class="n">mask</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">((</span><span class="n">maxlen</span><span class="p">),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">)[</span><span class="kc">None</span><span class="p">,</span> <span class="p">:]</span> <span class="o">&lt;</span> <span class="n">valid_len</span><span class="p">[:,</span> <span class="kc">None</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">    <span class="n">X</span><span class="p">[</span><span class="o">~</span><span class="n">mask</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">X</span> 
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">masked_softmax</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">valid_lens</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;通过在最后一个轴上掩蔽元素来执行softmax操作&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># X:3D张量，valid_lens:1D或2D张量</span>
</span></span><span class="line"><span class="cl">    <span class="k">if</span> <span class="n">valid_lens</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">        <span class="n">shape</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">valid_lens</span><span class="o">.</span><span class="n">dim</span><span class="p">()</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># 第一维上重复 shape[1] 次</span>
</span></span><span class="line"><span class="cl">            <span class="n">valid_lens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span><span class="n">valid_lens</span><span class="p">,</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># 转为一维</span>
</span></span><span class="line"><span class="cl">            <span class="n">valid_lens</span> <span class="o">=</span> <span class="n">valid_lens</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 最后一轴上被掩蔽的元素使用一个非常大的负值替换，从而其softmax输出为0</span>
</span></span><span class="line"><span class="cl">        <span class="n">X</span> <span class="o">=</span> <span class="n">sequence_mask</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]),</span> <span class="n">valid_lens</span><span class="p">,</span> <span class="n">value</span><span class="o">=-</span><span class="mf">1e6</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">shape</span><span class="p">),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">AdditiveAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;Additive attention&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key_size</span><span class="p">,</span> <span class="n">query_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">(</span><span class="n">AdditiveAttention</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">W_k</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">key_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">W_q</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">query_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">w_v</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">queries</span><span class="p">,</span> <span class="n">keys</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">valid_lens</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">queries</span><span class="p">,</span> <span class="n">keys</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_q</span><span class="p">(</span><span class="n">queries</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_k</span><span class="p">(</span><span class="n">keys</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">features</span> <span class="o">=</span> <span class="n">queries</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span> <span class="n">keys</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">features</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tanh</span><span class="p">(</span><span class="n">features</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">scores</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">w_v</span><span class="p">(</span><span class="n">features</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">attention_weights</span> <span class="o">=</span> <span class="n">masked_softmax</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">valid_lens</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attention_weights</span><span class="p">),</span> <span class="n">values</span><span class="p">)</span>
</span></span></code></pre></div><p>
    <figure>
      <img
        class="my-0 rounded-md"
        loading="lazy"
        srcset="
        /img/dl_attention_add_huecd1dc1443dde0f82f94290f23d588b6_1933524_330x0_resize_q75_box.jpg 330w,
        /img/dl_attention_add_huecd1dc1443dde0f82f94290f23d588b6_1933524_660x0_resize_q75_box.jpg 660w,
        /img/dl_attention_add_huecd1dc1443dde0f82f94290f23d588b6_1933524_1024x0_resize_q75_box.jpg 1024w,
        /img/dl_attention_add_huecd1dc1443dde0f82f94290f23d588b6_1933524_1320x0_resize_q75_box.jpg 2x"
        src="/img/dl_attention_add_huecd1dc1443dde0f82f94290f23d588b6_1933524_660x0_resize_q75_box.jpg"
        alt=""
      />
      
    </figure>
</p>


<h3 class="relative group">3.缩放点积注意力 
    <div id="3%E7%BC%A9%E6%94%BE%E7%82%B9%E7%A7%AF%E6%B3%A8%E6%84%8F%E5%8A%9B" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#3%E7%BC%A9%E6%94%BE%E7%82%B9%E7%A7%AF%E6%B3%A8%E6%84%8F%E5%8A%9B" aria-label="锚点">#</a>
    </span>        
    
</h3>
<p>$$
评分函数为：\
a(\mathbf q, \mathbf k) = \mathbf{q}^\top \mathbf{k}  /\sqrt{d}.\
基于n个查询和m个键－值对计算注意力，
其中查询和键的长度为d，值的长度为v。\
查询\mathbf Q\in\mathbb R^{n\times d}、
键\mathbf K\in\mathbb R^{m\times d}和
值\mathbf V\in\mathbb R^{m\times v}的缩放点积注意力是：\</p>
<p>\mathrm{softmax}\left(\frac{\mathbf Q \mathbf K^\top }{\sqrt{d}}\right) \mathbf V \in \mathbb{R}^{n\times v}.
$$
除以根号 <em>d</em> 让函数值不过大，使其不受序列长度的影响</p>


<h4 class="relative group"><strong>Latex 自带转PDF为SVG：pdftocairo -svg source.pdf</strong> 
    <div id="latex-%E8%87%AA%E5%B8%A6%E8%BD%ACpdf%E4%B8%BAsvgpdftocairo--svg-sourcepdf" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#latex-%E8%87%AA%E5%B8%A6%E8%BD%ACpdf%E4%B8%BAsvgpdftocairo--svg-sourcepdf" aria-label="锚点">#</a>
    </span>        
    
</h4>
<p>
    <figure>
      <img
        class="my-0 rounded-md"
        loading="lazy"
        srcset="
        /img/dl_attention_dot_hu00c3222f980887d8d56982f448acf600_1238917_330x0_resize_q75_box.jpg 330w,
        /img/dl_attention_dot_hu00c3222f980887d8d56982f448acf600_1238917_660x0_resize_q75_box.jpg 660w,
        /img/dl_attention_dot_hu00c3222f980887d8d56982f448acf600_1238917_1024x0_resize_q75_box.jpg 1024w,
        /img/dl_attention_dot_hu00c3222f980887d8d56982f448acf600_1238917_1320x0_resize_q75_box.jpg 2x"
        src="/img/dl_attention_dot_hu00c3222f980887d8d56982f448acf600_1238917_660x0_resize_q75_box.jpg"
        alt=""
      />
      
    </figure>
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">DotProductAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;缩放点积注意力&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">(</span><span class="n">DotProductAttention</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="c1"># queries的形状：(batch_size，查询的个数，d)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># keys的形状：(batch_size，“键－值”对的个数，d)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># values的形状：(batch_size，“键－值”对的个数，值的维度)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># valid_lens的形状:(batch_size，)或者(batch_size，查询的个数)</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">queries</span><span class="p">,</span> <span class="n">keys</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">valid_lens</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">d</span> <span class="o">=</span> <span class="n">queries</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 设置transpose_b=True为了交换keys的最后两个维度</span>
</span></span><span class="line"><span class="cl">        <span class="n">scores</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="n">queries</span><span class="p">,</span> <span class="n">keys</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">2</span><span class="p">))</span> <span class="o">/</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">attention_weights</span> <span class="o">=</span> <span class="n">masked_softmax</span><span class="p">(</span><span class="n">scores</span><span class="p">,</span> <span class="n">valid_lens</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">bmm</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">attention_weights</span><span class="p">),</span> <span class="n">values</span><span class="p">)</span>
</span></span></code></pre></div>

<h3 class="relative group">4.多头注意力 
    <div id="4%E5%A4%9A%E5%A4%B4%E6%B3%A8%E6%84%8F%E5%8A%9B" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#4%E5%A4%9A%E5%A4%B4%E6%B3%A8%E6%84%8F%E5%8A%9B" aria-label="锚点">#</a>
    </span>        
    
</h3>
<p>
    <figure>
      <img
        class="my-0 rounded-md"
        loading="lazy"
        src="/img/dl_multi-head-attention.svg"
        alt="dl_multi-head-attention"
      />
      
    </figure>

$$
给定查询\mathbf{q} \in \mathbb{R}^{d_q}、键\mathbf{k} \in \mathbb{R}^{d_k}和
值\mathbf{v} \in \mathbb{R}^{d_v}，
每个注意力头\mathbf{h}_i（i = 1, \ldots, h）的计算方法为：\</p>
<p>\mathbf{h}_i = f(\mathbf W_i^{(q)}\mathbf q, \mathbf W_i^{(k)}\mathbf k,\mathbf W_i^{(v)}\mathbf v) \in \mathbb R^{p_v},\</p>
<p>其中，可学习的参数包括
\mathbf W_i^{(q)}\in\mathbb R^{p_q\times d_q}、
\mathbf W_i^{(k)}\in\mathbb R^{p_k\times d_k}和
\mathbf W_i^{(v)}\in\mathbb R^{p_v\times d_v}，
以及代表注意力汇聚的函数f。
$$
<em>f</em> 可以是加性注意力和缩放点积注意力。多头注意力的输出需要经过另一个线性转换，它对应着 <em>h</em> 个头连结后的结果，因此其可学习参数是
$$
\mathbf W_o\in\mathbb R^{p_o\times h p_v}：\</p>
<p>\mathbf W_o \begin{bmatrix}\mathbf h_1\\vdots\\mathbf h_h\end{bmatrix} \in \mathbb{R}^{p_o}.
$$</p>
<p>在实现过程中通常<strong>选择缩放点积注意力作为每一个注意力头</strong>。</p>
<p>为了避免计算代价和参数代价的大幅增长，设定
$$
p_q = p_k = p_v = p_o / H
$$
值得注意的是，如果将查询、键和值的线性变换的输出数量设置为
$$
p_q H = p_k H = p_v H = p_o
$$
则可以并行计算 <em>H</em> 个头。</p>
<ul>
<li>
<p>代码中，<em>p_o = 隐藏层数 h</em> 。将 <strong>KQV</strong> 最后一维转为隐藏层数。</p>
</li>
<li>
<p>后转为 <strong>nH</strong> 批次，代表多头的头 <strong>H</strong>，如下图所示</p>
</li>
<li>
<p>放入先前的点积注意力块后得到形状 <strong>(nH, SQ, h/H)</strong> 的输出</p>
</li>
<li>
<p>拼接即：转为形状 <strong>(n, q, h)</strong> 的输出</p>
</li>
<li>
<p>输出经过线性层，得到形状 <strong>(n, q, h)</strong> 的输出</p>
</li>
</ul>
<p>
    <figure>
      <img
        class="my-0 rounded-md"
        loading="lazy"
        srcset="
        /img/dl_transpose_hu00c3222f980887d8d56982f448acf600_693380_330x0_resize_q75_box.jpg 330w,
        /img/dl_transpose_hu00c3222f980887d8d56982f448acf600_693380_660x0_resize_q75_box.jpg 660w,
        /img/dl_transpose_hu00c3222f980887d8d56982f448acf600_693380_1024x0_resize_q75_box.jpg 1024w,
        /img/dl_transpose_hu00c3222f980887d8d56982f448acf600_693380_1320x0_resize_q75_box.jpg 2x"
        src="/img/dl_transpose_hu00c3222f980887d8d56982f448acf600_693380_660x0_resize_q75_box.jpg"
        alt="dl_transpose"
      />
      
    </figure>
</p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">transpose_qkv</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;为了多注意力头的并行计算而变换形状&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 输入X的形状:(batch_size，查询或者“键－值”对的个数，num_hiddens)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 输出X的形状:(batch_size，查询或者“键－值”对的个数，num_heads，num_hiddens/num_heads)</span>
</span></span><span class="line"><span class="cl">    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">num_heads</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 输出X的形状:(batch_size，num_heads，查询或者“键－值”对的个数，num_hiddens/num_heads)</span>
</span></span><span class="line"><span class="cl">    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="c1"># 最终输出的形状:(batch_size*num_heads，查询或者“键－值”对的个数，num_hiddens/num_heads)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">3</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">def</span> <span class="nf">transpose_output</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;逆转transpose_qkv函数的操作&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>
</span></span><span class="line"><span class="cl">    <span class="n">X</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">permute</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    <span class="k">return</span> <span class="n">X</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">MultiHeadAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;多头注意力&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key_size</span><span class="p">,</span> <span class="n">query_size</span><span class="p">,</span> <span class="n">value_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                 <span class="n">num_heads</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">(</span><span class="n">MultiHeadAttention</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span> <span class="o">=</span> <span class="n">num_heads</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">DotProductAttention</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">W_q</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">query_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">W_k</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">key_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">W_v</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">value_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">W_o</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">bias</span><span class="o">=</span><span class="n">bias</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">queries</span><span class="p">,</span> <span class="n">keys</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">valid_lens</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># queries，keys，values的形状:</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># (batch_size，查询或者“键－值”对的个数，num_hiddens)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># valid_lens　的形状:</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># (batch_size，)或(batch_size，查询的个数)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 经过变换后，输出的queries，keys，values　的形状:</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># (batch_size*num_heads，查询或者“键－值”对的个数，</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># num_hiddens/num_heads)</span>
</span></span><span class="line"><span class="cl">        <span class="n">queries</span> <span class="o">=</span> <span class="n">transpose_qkv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_q</span><span class="p">(</span><span class="n">queries</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">keys</span> <span class="o">=</span> <span class="n">transpose_qkv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_k</span><span class="p">(</span><span class="n">keys</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">values</span> <span class="o">=</span> <span class="n">transpose_qkv</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">W_v</span><span class="p">(</span><span class="n">values</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">valid_lens</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># 在轴0，将第一项（标量或者矢量）复制num_heads次，</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># 然后如此复制第二项，然后诸如此类。</span>
</span></span><span class="line"><span class="cl">            <span class="n">valid_lens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">repeat_interleave</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">                <span class="n">valid_lens</span><span class="p">,</span> <span class="n">repeats</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># output的形状:(batch_size*num_heads，查询的个数，</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># num_hiddens/num_heads)</span>
</span></span><span class="line"><span class="cl">        <span class="n">output</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">queries</span><span class="p">,</span> <span class="n">keys</span><span class="p">,</span> <span class="n">values</span><span class="p">,</span> <span class="n">valid_lens</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># output_concat的形状:(batch_size，查询的个数，num_hiddens)</span>
</span></span><span class="line"><span class="cl">        <span class="n">output_concat</span> <span class="o">=</span> <span class="n">transpose_output</span><span class="p">(</span><span class="n">output</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_heads</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">W_o</span><span class="p">(</span><span class="n">output_concat</span><span class="p">)</span>
</span></span></code></pre></div><p>
    <figure>
      <img
        class="my-0 rounded-md"
        loading="lazy"
        srcset="
        /img/dl_multi_attention_dot_hu00c3222f980887d8d56982f448acf600_1330690_330x0_resize_q75_box.jpg 330w,
        /img/dl_multi_attention_dot_hu00c3222f980887d8d56982f448acf600_1330690_660x0_resize_q75_box.jpg 660w,
        /img/dl_multi_attention_dot_hu00c3222f980887d8d56982f448acf600_1330690_1024x0_resize_q75_box.jpg 1024w,
        /img/dl_multi_attention_dot_hu00c3222f980887d8d56982f448acf600_1330690_1320x0_resize_q75_box.jpg 2x"
        src="/img/dl_multi_attention_dot_hu00c3222f980887d8d56982f448acf600_1330690_660x0_resize_q75_box.jpg"
        alt="dl_multi_attention_dot"
      />
      
    </figure>
</p>


<h3 class="relative group">5.自注意力、位置编码 
    <div id="5%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#5%E8%87%AA%E6%B3%A8%E6%84%8F%E5%8A%9B%E4%BD%8D%E7%BD%AE%E7%BC%96%E7%A0%81" aria-label="锚点">#</a>
    </span>        
    
</h3>
<p>
    <figure>
      <img
        class="my-0 rounded-md"
        loading="lazy"
        src="/img/dl_self-attention.svg"
        alt="dl_self-attention"
      />
      
    </figure>

$$
给定一个由词元组成的输入序列\mathbf{x}_1, \ldots, \mathbf{x}_n，
其中任意\mathbf{x}_i \in \mathbb{R}^d（1 \leq i \leq n）。\
该序列的自注意力输出为一个长度相同的序列
\mathbf{y}_1, \ldots, \mathbf{y}_n，其中：\
\mathbf{y}_i = f(\mathbf{x}_i, (\mathbf{x}_1, \mathbf{x}_1), \ldots, (\mathbf{x}<em>n, \mathbf{x}<em>n)) \in \mathbb{R}^d
\\
对长度为n的序列\mathbf{X}\in \mathbb{R}^{n \times d} ，位置编码\mathbf{P} \in \mathbb{R}^{n \times d}输出\mathbf{X} + \mathbf{P}，
矩阵第i行、第2j列和2j+1列上的元素为：\
\begin{aligned} p</em>{i, 2j} &amp;= \sin\left(\frac{i}{10000^{2j/d}}\right),\p</em>{i, 2j+1} &amp;= \cos\left(\frac{i}{10000^{2j/d}}\right).\end{aligned}
$$
代码上自注意力即多头注意力<strong>KQV全部是输入</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">PositionalEncoding</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;位置编码&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">max_len</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">(</span><span class="n">PositionalEncoding</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 创建一个足够长的三维P</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">P</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">max_len</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">))</span> <span class="c1"># 批次为1</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># X形状：(max_len, num_hiddens/2)</span>
</span></span><span class="line"><span class="cl">        <span class="n">X</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">max_len</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="mi">10000</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">/</span> <span class="n">num_hiddens</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">P</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>   <span class="c1"># 偶数索引赋值</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">P</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>   <span class="c1"># 奇数索引赋值</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">X</span> <span class="o">=</span> <span class="n">X</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">P</span><span class="p">[:,</span> <span class="p">:</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">:]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="c1"># 避免对位置过于敏感</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl"><span class="c1">#########使用##########</span>
</span></span><span class="line"><span class="cl"><span class="n">encoding_dim</span><span class="p">,</span> <span class="n">num_steps</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span> <span class="mi">60</span>
</span></span><span class="line"><span class="cl"><span class="n">pos_encoding</span> <span class="o">=</span> <span class="n">PositionalEncoding</span><span class="p">(</span><span class="n">encoding_dim</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl"><span class="n">pos_encoding</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span>
</span></span><span class="line"><span class="cl"><span class="n">X</span> <span class="o">=</span> <span class="n">pos_encoding</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">encoding_dim</span><span class="p">)))</span>
</span></span></code></pre></div>

<h3 class="relative group">6.Transformer 
    <div id="6transformer" class="anchor"></div>
    
    <span
        class="absolute top-0 w-6 transition-opacity opacity-0 ltr:-left-6 rtl:-right-6 not-prose group-hover:opacity-100">
        <a class="group-hover:text-primary-300 dark:group-hover:text-neutral-700"
            style="text-decoration-line: none !important;" href="#6transformer" aria-label="锚点">#</a>
    </span>        
    
</h3>
<p>
    <figure>
      <img
        class="my-0 rounded-md"
        loading="lazy"
        src="/img/dl_transformer.svg"
        alt="transformer"
      />
      
    </figure>
</p>
<p><strong>输入编码</strong></p>
<p>
    <figure>
      <img
        class="my-0 rounded-md"
        loading="lazy"
        srcset="
        /img/dl_transformer_1_hu00c3222f980887d8d56982f448acf600_454101_330x0_resize_q75_box.jpg 330w,
        /img/dl_transformer_1_hu00c3222f980887d8d56982f448acf600_454101_660x0_resize_q75_box.jpg 660w,
        /img/dl_transformer_1_hu00c3222f980887d8d56982f448acf600_454101_1024x0_resize_q75_box.jpg 1024w,
        /img/dl_transformer_1_hu00c3222f980887d8d56982f448acf600_454101_1320x0_resize_q75_box.jpg 2x"
        src="/img/dl_transformer_1_hu00c3222f980887d8d56982f448acf600_454101_660x0_resize_q75_box.jpg"
        alt="dl_transformer_1"
      />
      
    </figure>
</p>
<p><strong>训练</strong></p>
<p>
    <figure>
      <img
        class="my-0 rounded-md"
        loading="lazy"
        srcset="
        /img/dl_transformer_2_hu00c3222f980887d8d56982f448acf600_2507030_330x0_resize_q75_box.jpg 330w,
        /img/dl_transformer_2_hu00c3222f980887d8d56982f448acf600_2507030_660x0_resize_q75_box.jpg 660w,
        /img/dl_transformer_2_hu00c3222f980887d8d56982f448acf600_2507030_1024x0_resize_q75_box.jpg 1024w,
        /img/dl_transformer_2_hu00c3222f980887d8d56982f448acf600_2507030_1320x0_resize_q75_box.jpg 2x"
        src="/img/dl_transformer_2_hu00c3222f980887d8d56982f448acf600_2507030_660x0_resize_q75_box.jpg"
        alt="dl_transformer_2"
      />
      
    </figure>
</p>
<p><strong>预测</strong></p>
<img src="img/dl_transformer_3.jpg" alt="dl_transformer_3" style="zoom:15%;" />
<p><strong>编码器</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">PositionWiseFFN</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;基于位置的前馈网络&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">ffn_num_input</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="p">,</span> <span class="n">ffn_num_outputs</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                 <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">(</span><span class="n">PositionWiseFFN</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">dense1</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">ffn_num_input</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">relu</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ReLU</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">dense2</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">ffn_num_hiddens</span><span class="p">,</span> <span class="n">ffn_num_outputs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense2</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dense1</span><span class="p">(</span><span class="n">X</span><span class="p">)))</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">AddNorm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;残差连接后进行层规范化&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">normalized_shape</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">(</span><span class="n">AddNorm</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">dropout</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">ln</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">LayerNorm</span><span class="p">(</span><span class="n">normalized_shape</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">ln</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">Y</span><span class="p">)</span> <span class="o">+</span> <span class="n">X</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">EncoderBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;Transformer编码器块&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key_size</span><span class="p">,</span> <span class="n">query_size</span><span class="p">,</span> <span class="n">value_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                 <span class="n">norm_shape</span><span class="p">,</span> <span class="n">ffn_num_input</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                 <span class="n">dropout</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">(</span><span class="n">EncoderBlock</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">attention</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">key_size</span><span class="p">,</span> <span class="n">query_size</span><span class="p">,</span> <span class="n">value_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">            <span class="n">use_bias</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">addnorm1</span> <span class="o">=</span> <span class="n">AddNorm</span><span class="p">(</span><span class="n">norm_shape</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span> <span class="o">=</span> <span class="n">PositionWiseFFN</span><span class="p">(</span><span class="n">ffn_num_input</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">addnorm2</span> <span class="o">=</span> <span class="n">AddNorm</span><span class="p">(</span><span class="n">norm_shape</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">valid_lens</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">Y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">addnorm1</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">valid_lens</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">addnorm2</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span><span class="p">(</span><span class="n">Y</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">TransformerEncoder</span><span class="p">(</span><span class="n">Encoder</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;Transformer编码器&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">key_size</span><span class="p">,</span> <span class="n">query_size</span><span class="p">,</span> <span class="n">value_size</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                 <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">norm_shape</span><span class="p">,</span> <span class="n">ffn_num_input</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                 <span class="n">num_heads</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">use_bias</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">(</span><span class="n">TransformerEncoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span> <span class="o">=</span> <span class="n">num_hiddens</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 将词汇表中的单词表示为连续的向量表示,初始化参数包括：num_embeddings：词汇表的大小 embedding_dim：嵌入向量的维度</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">pos_encoding</span> <span class="o">=</span> <span class="n">PositionalEncoding</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">blks</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">blks</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&#34;block&#34;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                <span class="n">EncoderBlock</span><span class="p">(</span><span class="n">key_size</span><span class="p">,</span> <span class="n">query_size</span><span class="p">,</span> <span class="n">value_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                             <span class="n">norm_shape</span><span class="p">,</span> <span class="n">ffn_num_input</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                             <span class="n">num_heads</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">use_bias</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">valid_lens</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 因为位置编码值在-1和1之间，</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># L2正则化=1，如果维度越大，里面的数值越小。</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 因此嵌入值乘以嵌入维度的平方根进行缩放，使得embedding的数值和位置编码数值差不多大小</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 然后再与位置编码相加。</span>
</span></span><span class="line"><span class="cl">        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_encoding</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 可视化使用</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">attention_weights</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">blks</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">blk</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">blks</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">X</span> <span class="o">=</span> <span class="n">blk</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">valid_lens</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">attention_weights</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">blk</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">attention_weights</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="n">X</span>
</span></span><span class="line"><span class="cl">    
</span></span></code></pre></div><p><strong>解码器</strong></p>
<div class="highlight"><pre tabindex="0" class="chroma"><code class="language-py" data-lang="py"><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">DecoderBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="s2">&#34;&#34;&#34;解码器中第i个块&#34;&#34;&#34;</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">key_size</span><span class="p">,</span> <span class="n">query_size</span><span class="p">,</span> <span class="n">value_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                 <span class="n">norm_shape</span><span class="p">,</span> <span class="n">ffn_num_input</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                 <span class="n">dropout</span><span class="p">,</span> <span class="n">i</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">(</span><span class="n">DecoderBlock</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">i</span> <span class="o">=</span> <span class="n">i</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">attention1</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">key_size</span><span class="p">,</span> <span class="n">query_size</span><span class="p">,</span> <span class="n">value_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">addnorm1</span> <span class="o">=</span> <span class="n">AddNorm</span><span class="p">(</span><span class="n">norm_shape</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">attention2</span> <span class="o">=</span> <span class="n">MultiHeadAttention</span><span class="p">(</span>
</span></span><span class="line"><span class="cl">            <span class="n">key_size</span><span class="p">,</span> <span class="n">query_size</span><span class="p">,</span> <span class="n">value_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">addnorm2</span> <span class="o">=</span> <span class="n">AddNorm</span><span class="p">(</span><span class="n">norm_shape</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span> <span class="o">=</span> <span class="n">PositionWiseFFN</span><span class="p">(</span><span class="n">ffn_num_input</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">addnorm3</span> <span class="o">=</span> <span class="n">AddNorm</span><span class="p">(</span><span class="n">norm_shape</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">enc_outputs</span><span class="p">,</span> <span class="n">enc_valid_lens</span> <span class="o">=</span> <span class="n">state</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">state</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 训练阶段，输出序列的所有词元都在同一时间处理，</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 因此state[2][self.i]初始化为None。</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 预测阶段，输出序列是通过词元一个接着一个解码的，</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 因此state[2][self.i]包含着直到当前时间步第i个块解码的输出表示</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="n">state</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="bp">self</span><span class="o">.</span><span class="n">i</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">key_values</span> <span class="o">=</span> <span class="n">X</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">key_values</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">((</span><span class="n">state</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="bp">self</span><span class="o">.</span><span class="n">i</span><span class="p">],</span> <span class="n">X</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">state</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="bp">self</span><span class="o">.</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">key_values</span>
</span></span><span class="line"><span class="cl">        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_steps</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># 训练时需要将后面的遮掉</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># dec_valid_lens的开头:(batch_size,num_steps), 其中每一行是[1,2,...,num_steps]</span>
</span></span><span class="line"><span class="cl">            <span class="n">dec_valid_lens</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">num_steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">X</span><span class="o">.</span><span class="n">device</span><span class="p">)</span><span class="o">.</span><span class="n">repeat</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">else</span><span class="p">:</span>
</span></span><span class="line"><span class="cl">            <span class="n">dec_valid_lens</span> <span class="o">=</span> <span class="kc">None</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">        <span class="c1"># 训练时:自注意力，预测时：非自注意力</span>
</span></span><span class="line"><span class="cl">        <span class="n">X2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention1</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">key_values</span><span class="p">,</span> <span class="n">key_values</span><span class="p">,</span> <span class="n">dec_valid_lens</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">Y</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">addnorm1</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">X2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 编码器－解码器注意力。</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># enc_outputs的开头:(batch_size,num_steps,num_hiddens)</span>
</span></span><span class="line"><span class="cl">        <span class="n">Y2</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">attention2</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">enc_outputs</span><span class="p">,</span> <span class="n">enc_outputs</span><span class="p">,</span> <span class="n">enc_valid_lens</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="n">Z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">addnorm2</span><span class="p">(</span><span class="n">Y</span><span class="p">,</span> <span class="n">Y2</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">addnorm3</span><span class="p">(</span><span class="n">Z</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">ffn</span><span class="p">(</span><span class="n">Z</span><span class="p">)),</span> <span class="n">state</span>
</span></span><span class="line"><span class="cl">    
</span></span><span class="line"><span class="cl"><span class="k">class</span> <span class="nc">TransformerDecoder</span><span class="p">(</span><span class="n">AttentionDecoder</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">,</span> <span class="n">key_size</span><span class="p">,</span> <span class="n">query_size</span><span class="p">,</span> <span class="n">value_size</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                 <span class="n">num_hiddens</span><span class="p">,</span> <span class="n">norm_shape</span><span class="p">,</span> <span class="n">ffn_num_input</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                 <span class="n">num_heads</span><span class="p">,</span> <span class="n">num_layers</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="nb">super</span><span class="p">(</span><span class="n">TransformerDecoder</span><span class="p">,</span> <span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span> <span class="o">=</span> <span class="n">num_hiddens</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span> <span class="o">=</span> <span class="n">num_layers</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">embedding</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">pos_encoding</span> <span class="o">=</span> <span class="n">PositionalEncoding</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">blks</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">()</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_layers</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">blks</span><span class="o">.</span><span class="n">add_module</span><span class="p">(</span><span class="s2">&#34;block&#34;</span><span class="o">+</span><span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">),</span>
</span></span><span class="line"><span class="cl">                <span class="n">DecoderBlock</span><span class="p">(</span><span class="n">key_size</span><span class="p">,</span> <span class="n">query_size</span><span class="p">,</span> <span class="n">value_size</span><span class="p">,</span> <span class="n">num_hiddens</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                             <span class="n">norm_shape</span><span class="p">,</span> <span class="n">ffn_num_input</span><span class="p">,</span> <span class="n">ffn_num_hiddens</span><span class="p">,</span>
</span></span><span class="line"><span class="cl">                             <span class="n">num_heads</span><span class="p">,</span> <span class="n">dropout</span><span class="p">,</span> <span class="n">i</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">dense</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_hiddens</span><span class="p">,</span> <span class="n">vocab_size</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">init_state</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">enc_outputs</span><span class="p">,</span> <span class="n">enc_valid_lens</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="p">[</span><span class="n">enc_outputs</span><span class="p">,</span> <span class="n">enc_valid_lens</span><span class="p">,</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="bp">self</span><span class="o">.</span><span class="n">num_layers</span><span class="p">]</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="n">X</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos_encoding</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">embedding</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">num_hiddens</span><span class="p">))</span>
</span></span><span class="line"><span class="cl">        <span class="c1"># 可视化使用</span>
</span></span><span class="line"><span class="cl">        <span class="bp">self</span><span class="o">.</span><span class="n">_attention_weights</span> <span class="o">=</span> <span class="p">[[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">blks</span><span class="p">)</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span> <span class="p">(</span><span class="mi">2</span><span class="p">)]</span>
</span></span><span class="line"><span class="cl">        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">blk</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">blks</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">            <span class="n">X</span><span class="p">,</span> <span class="n">state</span> <span class="o">=</span> <span class="n">blk</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">state</span><span class="p">)</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># 解码器自注意力权重</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">_attention_weights</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">blk</span><span class="o">.</span><span class="n">attention1</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">attention_weights</span>
</span></span><span class="line"><span class="cl">            <span class="c1"># “编码器－解码器”自注意力权重</span>
</span></span><span class="line"><span class="cl">            <span class="bp">self</span><span class="o">.</span><span class="n">_attention_weights</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">blk</span><span class="o">.</span><span class="n">attention2</span><span class="o">.</span><span class="n">attention</span><span class="o">.</span><span class="n">attention_weights</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">dense</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="n">state</span>
</span></span><span class="line"><span class="cl">
</span></span><span class="line"><span class="cl">    <span class="nd">@property</span>
</span></span><span class="line"><span class="cl">    <span class="k">def</span> <span class="nf">attention_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
</span></span><span class="line"><span class="cl">        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_attention_weights</span>
</span></span></code></pre></div>
        </div>
        
        

        
        
  
  <section class="flex flex-row flex-wrap justify-center pt-4 text-xl">
    
      
      <a
      target="_blank"
      class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
      href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://TCmatj.github.io/docs/python/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/&amp;title=%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0"
      title="分享到 LinkedIn"
      aria-label="分享到 LinkedIn"
      >
      

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>

  </span>


    </a>
      
    
      
      <a
      target="_blank"
      class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
      href="https://twitter.com/intent/tweet/?url=https://TCmatj.github.io/docs/python/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/&amp;text=%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0"
      title="分享到 Twitter"
      aria-label="分享到 Twitter"
      >
      

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z"/></svg>
  </span>


    </a>
      
    
      
      <a
      target="_blank"
      class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
      href="https://bsky.app/intent/compose?text=%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0&#43;https://TCmatj.github.io/docs/python/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"
      title=""
      aria-label=""
      >
      

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M256,232.562c-21.183,-41.196 -78.868,-117.97 -132.503,-155.834c-51.378,-36.272 -70.978,-29.987 -83.828,-24.181c-14.872,6.72 -17.577,29.554 -17.577,42.988c0,13.433 7.365,110.138 12.169,126.281c15.873,53.336 72.376,71.358 124.413,65.574c2.66,-0.395 5.357,-0.759 8.089,-1.097c-2.68,0.429 -5.379,0.796 -8.089,1.097c-76.259,11.294 -143.984,39.085 -55.158,137.972c97.708,101.165 133.908,-21.692 152.484,-83.983c18.576,62.291 39.972,180.718 150.734,83.983c83.174,-83.983 22.851,-126.674 -53.408,-137.969c-2.71,-0.302 -5.409,-0.667 -8.089,-1.096c2.732,0.337 5.429,0.702 8.089,1.096c52.037,5.785 108.54,-12.239 124.413,-65.574c4.804,-16.142 12.169,-112.847 12.169,-126.281c-0,-13.434 -2.705,-36.267 -17.577,-42.988c-12.85,-5.806 -32.45,-12.09 -83.829,24.181c-53.634,37.864 -111.319,114.635 -132.502,155.831Z"/></svg>
  </span>


    </a>
      
    
      
      <a
      target="_blank"
      class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
      href="https://reddit.com/submit/?url=https://TCmatj.github.io/docs/python/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/&amp;resubmit=true&amp;title=%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0"
      title="提交到 Reddit"
      aria-label="提交到 Reddit"
      >
      

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M201.5 305.5c-13.8 0-24.9-11.1-24.9-24.6 0-13.8 11.1-24.9 24.9-24.9 13.6 0 24.6 11.1 24.6 24.9 0 13.6-11.1 24.6-24.6 24.6zM504 256c0 137-111 248-248 248S8 393 8 256 119 8 256 8s248 111 248 248zm-132.3-41.2c-9.4 0-17.7 3.9-23.8 10-22.4-15.5-52.6-25.5-86.1-26.6l17.4-78.3 55.4 12.5c0 13.6 11.1 24.6 24.6 24.6 13.8 0 24.9-11.3 24.9-24.9s-11.1-24.9-24.9-24.9c-9.7 0-18 5.8-22.1 13.8l-61.2-13.6c-3-.8-6.1 1.4-6.9 4.4l-19.1 86.4c-33.2 1.4-63.1 11.3-85.5 26.8-6.1-6.4-14.7-10.2-24.1-10.2-34.9 0-46.3 46.9-14.4 62.8-1.1 5-1.7 10.2-1.7 15.5 0 52.6 59.2 95.2 132 95.2 73.1 0 132.3-42.6 132.3-95.2 0-5.3-.6-10.8-1.9-15.8 31.3-16 19.8-62.5-14.9-62.5zM302.8 331c-18.2 18.2-76.1 17.9-93.6 0-2.2-2.2-6.1-2.2-8.3 0-2.5 2.5-2.5 6.4 0 8.6 22.8 22.8 87.3 22.8 110.2 0 2.5-2.2 2.5-6.1 0-8.6-2.2-2.2-6.1-2.2-8.3 0zm7.7-75c-13.6 0-24.6 11.1-24.6 24.9 0 13.6 11.1 24.6 24.6 24.6 13.8 0 24.9-11.1 24.9-24.6 0-13.8-11-24.9-24.9-24.9z"/></svg>

  </span>


    </a>
      
    
      
      <a
      target="_blank"
      class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
      href="https://api.whatsapp.com/send?text=https://TCmatj.github.io/docs/python/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/&amp;resubmit=true&amp;title=%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0"
      title=""
      aria-label=""
      >
      

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path fill="currentColor" d="M380.9 97.1C339 55.1 283.2 32 223.9 32c-122.4 0-222 99.6-222 222 0 39.1 10.2 77.3 29.6 111L0 480l117.7-30.9c32.4 17.7 68.9 27 106.1 27h.1c122.3 0 224.1-99.6 224.1-222 0-59.3-25.2-115-67.1-157zm-157 341.6c-33.2 0-65.7-8.9-94-25.7l-6.7-4-69.8 18.3L72 359.2l-4.4-7c-18.5-29.4-28.2-63.3-28.2-98.2 0-101.7 82.8-184.5 184.6-184.5 49.3 0 95.6 19.2 130.4 54.1 34.8 34.9 56.2 81.2 56.1 130.5 0 101.8-84.9 184.6-186.6 184.6zm101.2-138.2c-5.5-2.8-32.8-16.2-37.9-18-5.1-1.9-8.8-2.8-12.5 2.8-3.7 5.6-14.3 18-17.6 21.8-3.2 3.7-6.5 4.2-12 1.4-32.6-16.3-54-29.1-75.5-66-5.7-9.8 5.7-9.1 16.3-30.3 1.8-3.7.9-6.9-.5-9.7-1.4-2.8-12.5-30.1-17.1-41.2-4.5-10.8-9.1-9.3-12.5-9.5-3.2-.2-6.9-.2-10.6-.2-3.7 0-9.7 1.4-14.8 6.9-5.1 5.6-19.4 19-19.4 46.3 0 27.3 19.9 53.7 22.6 57.4 2.8 3.7 39.1 59.7 94.8 83.8 35.2 15.2 49 16.5 66.6 13.9 10.7-1.6 32.8-13.4 37.4-26.4 4.6-13 4.6-24.1 3.2-26.4-1.3-2.5-5-3.9-10.5-6.6z"/></svg>

  </span>


    </a>
      
    
      
      <a
      target="_blank"
      class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
      href="https://t.me/share/url?url=https://TCmatj.github.io/docs/python/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/&amp;resubmit=true&amp;title=%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0"
      title=""
      aria-label=""
      >
      

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path fill="currentColor" d="M248,8C111.033,8,0,119.033,0,256S111.033,504,248,504,496,392.967,496,256,384.967,8,248,8ZM362.952,176.66c-3.732,39.215-19.881,134.378-28.1,178.3-3.476,18.584-10.322,24.816-16.948,25.425-14.4,1.326-25.338-9.517-39.287-18.661-21.827-14.308-34.158-23.215-55.346-37.177-24.485-16.135-8.612-25,5.342-39.5,3.652-3.793,67.107-61.51,68.335-66.746.153-.655.3-3.1-1.154-4.384s-3.59-.849-5.135-.5q-3.283.746-104.608,69.142-14.845,10.194-26.894,9.934c-8.855-.191-25.888-5.006-38.551-9.123-15.531-5.048-27.875-7.717-26.8-16.291q.84-6.7,18.45-13.7,108.446-47.248,144.628-62.3c68.872-28.647,83.183-33.623,92.511-33.789,2.052-.034,6.639.474,9.61,2.885a10.452,10.452,0,0,1,3.53,6.716A43.765,43.765,0,0,1,362.952,176.66Z"/></svg>

  </span>


    </a>
      
    
      
      <a
      target="_blank"
      class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
      href="https://pinterest.com/pin/create/bookmarklet/?url=https://TCmatj.github.io/docs/python/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/&amp;description=%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0"
      title="钉到 Pinterest"
      aria-label="钉到 Pinterest"
      >
      

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path fill="currentColor" d="M496 256c0 137-111 248-248 248-25.6 0-50.2-3.9-73.4-11.1 10.1-16.5 25.2-43.5 30.8-65 3-11.6 15.4-59 15.4-59 8.1 15.4 31.7 28.5 56.8 28.5 74.8 0 128.7-68.8 128.7-154.3 0-81.9-66.9-143.2-152.9-143.2-107 0-163.9 71.8-163.9 150.1 0 36.4 19.4 81.7 50.3 96.1 4.7 2.2 7.2 1.2 8.3-3.3.8-3.4 5-20.3 6.9-28.1.6-2.5.3-4.7-1.7-7.1-10.1-12.5-18.3-35.3-18.3-56.6 0-54.7 41.4-107.6 112-107.6 60.9 0 103.6 41.5 103.6 100.9 0 67.1-33.9 113.6-78 113.6-24.3 0-42.6-20.1-36.7-44.8 7-29.5 20.5-61.3 20.5-82.6 0-19-10.2-34.9-31.4-34.9-24.9 0-44.9 25.7-44.9 60.2 0 22 7.4 36.8 7.4 36.8s-24.5 103.8-29 123.2c-5 21.4-3 51.6-.9 71.2C65.4 450.9 0 361.1 0 256 0 119 111 8 248 8s248 111 248 248z"/></svg>

  </span>


    </a>
      
    
      
      <a
      target="_blank"
      class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
      href="https://www.facebook.com/sharer/sharer.php?u=https://TCmatj.github.io/docs/python/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/&amp;quote=%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0"
      title="分享到 Facebook"
      aria-label="分享到 Facebook"
      >
      

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14 0 55.52 4.84 55.52 4.84v61h-31.28c-30.8 0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z"/></svg>

  </span>


    </a>
      
    
      
      <a
      target="_blank"
      class="m-1 rounded bg-neutral-300 p-1.5 text-neutral-700 hover:bg-primary-500 hover:text-neutral dark:bg-neutral-700 dark:text-neutral-300 dark:hover:bg-primary-400 dark:hover:text-neutral-800"
      href="mailto:?body=https://TCmatj.github.io/docs/python/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/&amp;subject=%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0"
      title="通过电子邮件发送"
      aria-label="通过电子邮件发送"
      >
      

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M207.8 20.73c-93.45 18.32-168.7 93.66-187 187.1c-27.64 140.9 68.65 266.2 199.1 285.1c19.01 2.888 36.17-12.26 36.17-31.49l.0001-.6631c0-15.74-11.44-28.88-26.84-31.24c-84.35-12.98-149.2-86.13-149.2-174.2c0-102.9 88.61-185.5 193.4-175.4c91.54 8.869 158.6 91.25 158.6 183.2l0 16.16c0 22.09-17.94 40.05-40 40.05s-40.01-17.96-40.01-40.05v-120.1c0-8.847-7.161-16.02-16.01-16.02l-31.98 .0036c-7.299 0-13.2 4.992-15.12 11.68c-24.85-12.15-54.24-16.38-86.06-5.106c-38.75 13.73-68.12 48.91-73.72 89.64c-9.483 69.01 43.81 128 110.9 128c26.44 0 50.43-9.544 69.59-24.88c24 31.3 65.23 48.69 109.4 37.49C465.2 369.3 496 324.1 495.1 277.2V256.3C495.1 107.1 361.2-9.332 207.8 20.73zM239.1 304.3c-26.47 0-48-21.56-48-48.05s21.53-48.05 48-48.05s48 21.56 48 48.05S266.5 304.3 239.1 304.3z"/></svg>

  </span>


    </a>
      
    
  </section>


        


  
      </div>
     
      
      
        
        
          
          
        
      <script>
        var oid = "views_docs\/Python\/深度学习\/index.md"
        var oid_likes = "likes_docs\/Python\/深度学习\/index.md"
      </script>
      
      
      
      <script type="text/javascript" src="/js/page.min.0860cf4e04fa2d72cc33ddba263083464d48f67de06114529043cb4623319efed4f484fd7f1730df5abea0e2da6f3538855634081d02f2d6e920b956f063e823.js" integrity="sha512-CGDPTgT6LXLMM926JjCDRk1I9n3gYRRSkEPLRiMxnv7U9IT9fxcw31q&#43;oOLabzU4hVY0CB0C8tbpILlW8GPoIw=="></script>
  
    </section>
  <footer class="pt-8 max-w-prose print:hidden">

    
  
    
    
    
    <div class="pt-8">
      <hr class="border-dotted border-neutral-300 dark:border-neutral-600" />
      <div class="flex justify-between pt-3">
        <span>
          
            <a class="flex group mr-3" href="/docs/%E5%85%B6%E4%BB%96/%E7%AE%97%E6%B3%95/">
              <span
                class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400"
                >&larr;</span
              >
              <span
                class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400"
                >&rarr;</span
              >
              <span class="flex flex-col">
                <span
                  class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500"
                  >算法</span
                >
                <span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">
                  
                    <time datetime="0001-01-01 00:00:00 &#43;0000 UTC">0001-01-01</time>
                  
                </span>
              </span>
            </a>
          
        </span>
        <span>
          
            <a class="flex text-right group ml-3" href="/docs/%E5%85%B6%E4%BB%96/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/">
              <span class="flex flex-col">
                <span
                  class="mt-[0.1rem] leading-6 group-hover:underline group-hover:decoration-primary-500"
                  >设计模式</span
                >
                <span class="mt-[0.1rem] text-xs text-neutral-500 dark:text-neutral-400">
                  
                    <time datetime="0001-01-01 00:00:00 &#43;0000 UTC">0001-01-01</time>
                  
                </span>
              </span>
              <span
                class="ml-3 text-neutral-700 group-hover:text-primary-600 ltr:inline rtl:hidden dark:text-neutral dark:group-hover:text-primary-400"
                >&rarr;</span
              >
              <span
                class="mr-3 text-neutral-700 group-hover:text-primary-600 ltr:hidden rtl:inline dark:text-neutral dark:group-hover:text-primary-400"
                >&larr;</span
              >
            </a>
          
        </span>
      </div>
    </div>
  


    
  </footer>
</article>

      <div id="top-scroller" class="pointer-events-none absolute top-[110vh] bottom-0 w-12 ltr:right-0 rtl:left-0">
  <a href="#the-top"
    class="pointer-events-auto sticky top-[calc(100vh-5.5rem)] flex h-12 w-12 mb-16 items-center justify-center rounded-full bg-neutral/50 text-xl text-neutral-700 hover:text-primary-600 dark:bg-neutral-800/50 dark:text-neutral dark:hover:text-primary-400"
    aria-label="返回顶部" title="返回顶部">
    &uarr;
  </a>
</div>
    </main><footer id="site-footer" class="py-10 print:hidden">
  
  
    
    <nav class="flex flex-row pb-4 text-base font-medium text-neutral-500 dark:text-neutral-400">
      <ul class="flex flex-col list-none sm:flex-row">
        
        <li class="flex mb-1 ltr:text-right rtl:text-left sm:mb-0 ltr:sm:mr-7 ltr:sm:last:mr-0 rtl:sm:ml-7 rtl:sm:last:ml-0">
          <a class="decoration-primary-500 hover:underline hover:decoration-2 hover:underline-offset-2 flex items-center" href="/tags/"
            title="">
            
            标签
          </a>
        </li>
        
      </ul>
    </nav>
    
  
  <div class="flex items-center justify-between">

    
    
    <p class="text-sm text-neutral-500 dark:text-neutral-400">
      &copy;
      2024
      TCmatj
    </p>
    

    
    
    <p class="text-xs text-neutral-500 dark:text-neutral-400">
      
      
      由 <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500"
        href="https://gohugo.io/" target="_blank" rel="noopener noreferrer">Hugo</a> &amp; <a class="hover:underline hover:decoration-primary-400 hover:text-primary-500"
        href="https://blowfish.page/" target="_blank" rel="noopener noreferrer">Blowfish</a> 强力驱动
    </p>
    

  </div>
  <script>
    
    mediumZoom(document.querySelectorAll("img:not(.nozoom)"), {
      margin: 24,
      background: 'rgba(0,0,0,0.5)',
      scrollOffset: 0,
    })
    
  </script>
  
  
  <script type="text/javascript" src="/js/process.min.ee03488f19c93c2efb199e2e3014ea5f3cb2ce7d45154adb3399a158cac27ca52831db249ede5bb602700ef87eb02434139de0858af1818ab0fb4182472204a4.js" integrity="sha512-7gNIjxnJPC77GZ4uMBTqXzyyzn1FFUrbM5mhWMrCfKUoMdsknt5btgJwDvh&#43;sCQ0E53ghYrxgYqw&#43;0GCRyIEpA=="></script>
  
  
  <a rel="me" href="https://masto.ai/@blowfish"></a>
  
</footer>
<div
  id="search-wrapper"
  class="invisible fixed inset-0 flex h-screen w-screen cursor-default flex-col bg-neutral-500/50 p-4 backdrop-blur-sm dark:bg-neutral-900/50 sm:p-6 md:p-[10vh] lg:p-[12vh]"
  data-url="https://TCmatj.github.io/"
  style="z-index:500"
>
  <div
    id="search-modal"
    class="flex flex-col w-full max-w-3xl min-h-0 mx-auto border rounded-md shadow-lg top-20 border-neutral-200 bg-neutral dark:border-neutral-700 dark:bg-neutral-800"
  >
    <header class="relative z-10 flex items-center justify-between flex-none px-2">
      <form class="flex items-center flex-auto min-w-0">
        <div class="flex items-center justify-center w-8 h-8 text-neutral-400">
          

  <span class="relative block icon">
    <svg aria-hidden="true" focusable="false" data-prefix="fas" data-icon="search" class="svg-inline--fa fa-search fa-w-16" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M505 442.7L405.3 343c-4.5-4.5-10.6-7-17-7H372c27.6-35.3 44-79.7 44-128C416 93.1 322.9 0 208 0S0 93.1 0 208s93.1 208 208 208c48.3 0 92.7-16.4 128-44v16.3c0 6.4 2.5 12.5 7 17l99.7 99.7c9.4 9.4 24.6 9.4 33.9 0l28.3-28.3c9.4-9.4 9.4-24.6.1-34zM208 336c-70.7 0-128-57.2-128-128 0-70.7 57.2-128 128-128 70.7 0 128 57.2 128 128 0 70.7-57.2 128-128 128z"/></svg>

  </span>


        </div>
        <input
          type="search"
          id="search-query"
          class="flex flex-auto h-12 mx-1 bg-transparent appearance-none focus:outline-dotted focus:outline-2 focus:outline-transparent"
          placeholder="搜索"
          tabindex="0"
        />
      </form>
      <button
        id="close-search-button"
        class="flex items-center justify-center w-8 h-8 text-neutral-700 hover:text-primary-600 dark:text-neutral dark:hover:text-primary-400"
        title="关闭 (Esc)"
      >
        

  <span class="relative block icon">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 320 512"><path fill="currentColor" d="M310.6 361.4c12.5 12.5 12.5 32.75 0 45.25C304.4 412.9 296.2 416 288 416s-16.38-3.125-22.62-9.375L160 301.3L54.63 406.6C48.38 412.9 40.19 416 32 416S15.63 412.9 9.375 406.6c-12.5-12.5-12.5-32.75 0-45.25l105.4-105.4L9.375 150.6c-12.5-12.5-12.5-32.75 0-45.25s32.75-12.5 45.25 0L160 210.8l105.4-105.4c12.5-12.5 32.75-12.5 45.25 0s12.5 32.75 0 45.25l-105.4 105.4L310.6 361.4z"/></svg>

  </span>


      </button>
    </header>
    <section class="flex-auto px-2 overflow-auto">
      <ul id="search-results">
        
      </ul>
    </section>
  </div>
</div>

  </div>
</body>

<script data-name="BMC-Widget" data-cfasync="false" src="https://cdnjs.buymeacoffee.com/1.0.0/widget.prod.min.js"
  data-id="nunocoracao" data-description="Support me on Buy me a coffee!" data-message=""
  data-color="#FFDD00" data-position="Right" data-x_margin="18" data-y_margin="18"></script>

</html>
